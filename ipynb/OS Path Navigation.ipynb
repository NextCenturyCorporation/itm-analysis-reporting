{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')\n",
    "from FRVRS import nu, fu\n",
    "nu.delete_ipynb_checkpoint_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attempt to read CSV file using pandas; if unsuccessful, try using a reader                                           51\n",
       "Set the MCIVR metrics types                                                                                          51\n",
       "Section off player actions by session start and end                                                                  51\n",
       "[nan]                                                                                                                13\n",
       "(199476, 126)                                                                                                         5\n",
       "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_csv_stats_df.pkl.                 4\n",
       "                record_count                                                                                          4\n",
       "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl.     3\n",
       "                  record_count                                                                                        3\n",
       "(51, 3548)                                                                                                            3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pandas import Series\n",
    "lines_str = r\"\"\"\"\"\"\n",
    "Series(lines_str.split('\\n')).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS.notebook_utils import NotebookUtilities\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path='/mnt/c/Users/DaveBabbitt/Downloads/data',\n",
    "    saves_folder_path='/mnt/c/Users/DaveBabbitt/Downloads/saves'\n",
    ")\n",
    "\n",
    "from FRVRS.frvrs_utils import FRVRSUtilities\n",
    "fu = FRVRSUtilities(\n",
    "    data_folder_path='/mnt/c/Users/DaveBabbitt/Downloads/data',\n",
    "    saves_folder_path='/mnt/c/Users/DaveBabbitt/Downloads/saves'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_csv_stats_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Downloads/saves/pkl/metrics_evaluation_open_world_anova_df.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_csv_stats_df='', metrics_evaluation_open_world_json_stats_df='',\n",
    "    metrics_evaluation_open_world_scene_stats_df='', metrics_evaluation_open_world_anova_df=''\n",
    ")\n",
    "metrics_evaluation_open_world_csv_stats_df = data_frames_dict['metrics_evaluation_open_world_csv_stats_df']\n",
    "metrics_evaluation_open_world_json_stats_df = data_frames_dict['metrics_evaluation_open_world_json_stats_df']\n",
    "metrics_evaluation_open_world_scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']\n",
    "metrics_evaluation_open_world_anova_df = data_frames_dict['metrics_evaluation_open_world_anova_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get column and value descriptions\n",
      "Fix the doubled up descriptions\n",
      "Append the new row to the DataFrame\n",
      "Get a copy of the row\n",
      "Modify the desired column value\n",
      "Append the new row to the DataFrame\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os import listdir as listdir, makedirs as makedirs, path as osp, remove as remove, sep as sep, walk as walk\n",
    "from pandas import CategoricalDtype, DataFrame, Index, NaT, Series, concat, isna, notnull, read_csv, read_excel, read_pickle, to_datetime, to_numeric\n",
    "import re\n",
    "\n",
    "print(\"Get column and value descriptions\")\n",
    "file_path = osp.join(fu.data_folder, 'xlsx', 'Metrics_Evaluation_Dataset_organization_for_BBAI.xlsx')\n",
    "dataset_organization_df = read_excel(file_path)\n",
    "\n",
    "print(\"Fix the doubled up descriptions\")\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: ';' in str(x))\n",
    "for row_index, label in dataset_organization_df[mask_series].Labels.items():\n",
    "    labels_list = re.split(' *; *', str(label), 0)\n",
    "    dataset_organization_df.loc[row_index, 'Labels'] = labels_list[0]\n",
    "    \n",
    "    # Get a copy of the row\n",
    "    new_row = dataset_organization_df.loc[row_index].copy()\n",
    "    \n",
    "    # Modify the desired column value\n",
    "    new_row['Labels'] = labels_list[1]\n",
    "    \n",
    "    print(\"Append the new row to the DataFrame\")\n",
    "    dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "print(\"Get a copy of the row\")\n",
    "mask_series = (dataset_organization_df.Variable == 'AD_Del_Omni')\n",
    "new_row = dataset_organization_df.loc[mask_series].copy()\n",
    "\n",
    "print(\"Modify the desired column value\")\n",
    "new_row['Variable'] = 'AD_Del_Omni_Text'\n",
    "\n",
    "print(\"Append the new row to the DataFrame\")\n",
    "dataset_organization_df = concat([dataset_organization_df, new_row], ignore_index=True)\n",
    "\n",
    "# Get the column value descriptions\n",
    "mask_series = ~dataset_organization_df.Description.isnull()\n",
    "df = dataset_organization_df[mask_series]\n",
    "value_description_dict = df.set_index('Variable').Description.to_dict()\n",
    "new_description_dict = value_description_dict.copy()\n",
    "for k, v in value_description_dict.items():\n",
    "    new_description_dict[k] = v\n",
    "    if (not k.endswith('_Text')):\n",
    "        new_key_name = f'{k}_Text'\n",
    "        new_description_dict[new_key_name] = new_description_dict.get(new_key_name, v)\n",
    "value_description_dict = new_description_dict.copy()\n",
    "\n",
    "numeric_categories_mask_series = dataset_organization_df.Labels.map(lambda x: '=' in str(x))\n",
    "value_descriptions_columns = dataset_organization_df[numeric_categories_mask_series].Variable.unique().tolist()\n",
    "def get_value_description(column_name, column_value):\n",
    "    value_description = ''\n",
    "    if not isna(column_value):\n",
    "        mask_series = (dataset_organization_df.Variable == column_name) & ~dataset_organization_df.Labels.isnull()\n",
    "        if mask_series.any():\n",
    "            df = dataset_organization_df[mask_series]\n",
    "            mask_series = df.Labels.map(lambda label: re.split(' *= *', str(label), 0)[0] == str(int(float(column_value))))\n",
    "            if mask_series.any():\n",
    "                label = df[mask_series].Labels.squeeze()\n",
    "                value_description = re.split(' *= *', str(label), 0)[1]\n",
    "    \n",
    "    return value_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 record_count\n",
      "medical_role                 \n",
      "Other                      32\n",
      "Medical student            17\n",
      "EM faculty                  6\n",
      "Paramedic                   5\n",
      "EM resident                 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from numpy import nan, isnan\n",
    "\n",
    "# Add medical role back in\n",
    "new_column = 'MedRole'\n",
    "column_name = 'medical_role'\n",
    "if new_column in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "    on_columns = sorted(set(metrics_evaluation_open_world_anova_df.columns).intersection(set(metrics_evaluation_open_world_json_stats_df.columns)))\n",
    "    columns_list = on_columns + [new_column]\n",
    "    metrics_evaluation_open_world_anova_df = metrics_evaluation_open_world_anova_df.merge(\n",
    "        metrics_evaluation_open_world_json_stats_df[columns_list], on=on_columns, how='left'\n",
    "    ).rename(columns={new_column: column_name})\n",
    "    metrics_evaluation_open_world_anova_df[column_name] = metrics_evaluation_open_world_anova_df[column_name].map(\n",
    "        lambda cv: get_value_description('MedRole', cv)\n",
    "    ).replace('', nan)\n",
    "print(metrics_evaluation_open_world_anova_df.groupby(column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  record_count\n",
      "encounter_layout              \n",
      "Desert                      20\n",
      "Submarine                   18\n",
      "Jungle                      17\n",
      "Urban                       13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add the sim environment back in\n",
    "new_column = 'encounter_layout'\n",
    "if new_column in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "    on_columns = sorted(set(metrics_evaluation_open_world_anova_df.columns).intersection(set(metrics_evaluation_open_world_json_stats_df.columns)))\n",
    "    columns_list = on_columns + [new_column]\n",
    "    metrics_evaluation_open_world_anova_df = metrics_evaluation_open_world_anova_df.merge(\n",
    "        metrics_evaluation_open_world_json_stats_df[columns_list], on=on_columns, how='left'\n",
    "    )\n",
    "print(metrics_evaluation_open_world_anova_df.groupby(new_column).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from datetime import timedelta\n",
    "from pandas import DataFrame\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['os.DirEntry', 'os.O_DIRECT', 'os.O_DIRECTORY', 'os.ST_NODIRATIME', 'os.chdir', 'os.curdir', 'os.fchdir', 'os.listdir', 'os.makedirs', 'os.mkdir', 'os.pardir', 'os.removedirs', 'os.rmdir', 'os.scandir', 'os.supports_dir_fd']\n",
      "['osp.curdir', 'osp.dirname', 'osp.isdir', 'osp.pardir']\n",
      "['nu.github_folder']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([f'os.{fn}' for fn in dir(os) if 'dir' in fn.lower()])\n",
    "print([f'osp.{fn}' for fn in dir(osp) if 'dir' in fn.lower()])\n",
    "print([f'nu.{fn}' for fn in dir(nu) if 'github' in fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['os.__name__', 'os.confstr_names', 'os.name', 'os.pathconf_names', 'os.rename', 'os.renames', 'os.sysconf_names', 'os.ttyname', 'os.uname', 'os.uname_result']\n",
      "['osp.__name__', 'osp.basename', 'osp.dirname', 'osp.supports_unicode_filenames']\n",
      "['nu.get_filename_from_url']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print([f'os.{fn}' for fn in dir(os) if 'name' in fn.lower()])\n",
    "print([f'osp.{fn}' for fn in dir(osp) if 'name' in fn.lower()])\n",
    "print([f'nu.{fn}' for fn in dir(nu) if 'name' in fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attic.ipynb', 'Installs.ipynb', 'OS Path Navigation.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.listdir(path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "open_world\n",
      "Analyze OW Patient Stats.ipynb\n",
      "Correct SORT Order Metric for Metrics Evaluation Open World.ipynb\n",
      "Data Fixes for Metrics Evaluation Open World.ipynb\n",
      "Dataset Built for Metrics Evaluation Open World.ipynb\n",
      "Examine Freeform Open World ADM JSON Files.ipynb\n",
      "Exploratory Analysis of Open World ITM Data.ipynb\n",
      "Explore OW Participants and Scenes.ipynb\n",
      "File Stats Created for Metrics Evaluation Open World.ipynb\n",
      "Scene Stats Created for Metrics Evaluation Open World.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sub_directory, directories_list, files_list in os.walk(nu.github_folder):\n",
    "    file_names_list = []\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith('.ipynb') and re.search(r'(\\bOW\\b|Open(_|%20| )World)', file_name):\n",
    "            file_names_list.append(file_name)\n",
    "    if file_names_list:\n",
    "        print()\n",
    "        print(sub_directory.split('/')[-1])\n",
    "        print('\\n'.join(file_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the starting directory\n",
    "root_dir = '/'\n",
    "\n",
    "# Use a recursive function to search for matching folders\n",
    "def find_python311_folders(directory):\n",
    "    found_folders = []\n",
    "    try: entries_list = os.scandir(directory)\n",
    "    except: entries_list = []\n",
    "    for entry in entries_list:\n",
    "        try: is_entry_dir = entry.is_dir()\n",
    "        except: is_entry_dir = False\n",
    "        if is_entry_dir:\n",
    "            \n",
    "            # Check if the current entry is the target folder\n",
    "            if entry.name == \"python3.11\": found_folders.append(os.path.join(directory, entry.name))\n",
    "            \n",
    "            # Recursively search subdirectories (except the target folder)\n",
    "            elif entry.name != \"python3.11\": found_folders.extend(find_python311_folders(os.path.join(directory, entry.name)))\n",
    "    \n",
    "    return found_folders\n",
    "\n",
    "# Start the search from the root directory\n",
    "python311_folders = find_python311_folders(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the found folders\n",
    "print(f\"Found python3.11 folders: {', '.join(python311_folders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Print out a section of the .gitignore\n",
    "black_list = ['.ipynb_checkpoints', '$Recycle.Bin', '.git']\n",
    "print()\n",
    "print('# exclude everything except personal directories')\n",
    "print('/*')\n",
    "print('!.gitignore')\n",
    "for sub_directory in os.listdir(nu.github_folder):\n",
    "    if all(map(lambda x: x not in sub_directory, black_list)) and osp.isdir(osp.join(nu.github_folder, sub_directory)): print(f'!/{sub_directory}')\n",
    "print('!README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_set = set()\n",
    "for pickle_name in [fn.split('.')[0] for fn in os.listdir(s.saves_pickle_folder)]:\n",
    "    if pickle_name.endswith('_df'):\n",
    "        df = nu.load_object(pickle_name)\n",
    "        columns_set.update(df.columns[list(map(lambda x: ('year' in x) and (('begin' in x) or ('end' in x)), df.columns))])\n",
    "columns_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'Intel64 Family 6 Model 60 Stepping 3, GenuineIntel'\n",
    "import platform\n",
    "\n",
    "platform.processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
