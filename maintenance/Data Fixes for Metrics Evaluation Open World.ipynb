{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d497083-b501-4f84-bca7-d691eded680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16caa025-311a-4cf5-a53a-7258640a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load libraries\n",
    "from FRVRS import nu, fu\n",
    "import os.path as osp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe874fd-4fdb-47b2-aec5-0c09e07cc1e4",
   "metadata": {},
   "source": [
    "\n",
    "# Data Fixes for Metrics Evaluation Open World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8efbc6-3281-42a4-8c8e-4fe8062b7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_file_stats_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_df='', metrics_evaluation_open_world_file_stats_df='', metrics_evaluation_open_world_scene_stats_df=''\n",
    ")\n",
    "metrics_evaluation_open_world_df = data_frames_dict['metrics_evaluation_open_world_df']\n",
    "metrics_evaluation_open_world_file_stats_df = data_frames_dict['metrics_evaluation_open_world_file_stats_df']\n",
    "metrics_evaluation_open_world_scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df161d2-7b15-40a4-b0dd-e07e4d7359ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171766, 107)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scene_columns_set = set(metrics_evaluation_open_world_scene_stats_df.columns)\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "intersection_columns = set(['is_scene_aborted'])\n",
    "\n",
    "# Drop the logs columns already recorded in the scene stats data frames\n",
    "drop_columns = sorted(scene_columns_set.intersection(logs_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_df = metrics_evaluation_open_world_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_df.shape) # (171766, 107)\n",
    "    nu.store_objects(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedcd61f-86f0-4f26-a82d-5b78998ceb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171766, 108)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "file_columns_set = set(metrics_evaluation_open_world_file_stats_df.columns)\n",
    "intersection_columns = set(['file_name', 'logger_version', 'is_scene_aborted', 'csv_file_name'])\n",
    "\n",
    "# Drop the logs columns already recorded in the file and scene stats data frames\n",
    "drop_columns = list(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_df = metrics_evaluation_open_world_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_df.shape) # (171766, 109)\n",
    "    nu.store_objects(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4385ef6-f73f-4ca5-a108-6c430acf3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3563)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_file_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_file_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "file_columns_set = set(metrics_evaluation_open_world_file_stats_df.columns)\n",
    "intersection_columns = set([\n",
    "    'injury_record_injury_treated', 'injury_record_injury_treated_with_wrong_treatment', 'patient_demoted_health_level', 'patient_demoted_health_time_remaining',\n",
    "    'patient_demoted_hearing', 'patient_hearing', 'patient_record_health_level', 'patient_record_hearing', 'player_location_left_hand_location',\n",
    "    'player_location_right_hand_location', 'bag_access_location', 'patient_engaged_health_level', 'voice_capture_command_description'\n",
    "])\n",
    "\n",
    "# Drop the file stats columns that came with the process but are covered well enough in the logs data frame and add no value here\n",
    "drop_columns = sorted(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_file_stats_df = metrics_evaluation_open_world_file_stats_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_file_stats_df.shape) # (43, 3567)\n",
    "    nu.store_objects(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dacb6c3-2baa-421c-b1c9-bb21fdb2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_columns_set = set(metrics_evaluation_open_world_file_stats_df.columns)\n",
    "scene_columns_set = set(metrics_evaluation_open_world_scene_stats_df.columns)\n",
    "intersection_columns = set(['logger_version'])\n",
    "\n",
    "# Drop the scene columns already recorded in the file stats data frames\n",
    "drop_columns = sorted(file_columns_set.intersection(scene_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_scene_stats_df = metrics_evaluation_open_world_scene_stats_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_scene_stats_df.shape) # (76, 48)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fe582d-0a3f-40bf-8d7d-9448334c0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the file stats data frame\n",
    "subset_columns = ['session_uuid']\n",
    "mask_series = metrics_evaluation_open_world_file_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    metrics_evaluation_open_world_file_stats_df = metrics_evaluation_open_world_file_stats_df[~mask_series]\n",
    "    print(metrics_evaluation_open_world_file_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac18b354-2d34-444e-aa76-eda3be7b52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the scene stats data frame\n",
    "subset_columns = ['session_uuid', 'scene_id']\n",
    "mask_series = metrics_evaluation_open_world_scene_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    metrics_evaluation_open_world_scene_stats_df = metrics_evaluation_open_world_scene_stats_df[~mask_series]\n",
    "    print(metrics_evaluation_open_world_scene_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7a30-006e-480d-8531-9585d5526dde",
   "metadata": {},
   "source": [
    "\n",
    "## Provide Correctly Grouped Responder Type Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dac8e96-dc5b-4708-b384-c393a86f867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/first_responder_master_registry_file_stats_df.pkl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EM Resident', 'EMT-Basic', 'Medical Student', 'Other', 'Paramedic']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_frames_dict = nu.load_data_frames(first_responder_master_registry_file_stats_df='')\n",
    "df = data_frames_dict['first_responder_master_registry_file_stats_df']\n",
    "mask_series = ~df.responder_category.isnull()\n",
    "sorted(df[mask_series].responder_category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7561ce57-9574-4507-a997-cb6504d12f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_file_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_file_stats_df.csv\n",
      "(43, 3564)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responder_category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM Resident</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    record_count\n",
       "responder_category              \n",
       "EM Resident                   43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add a column that correctly groups responder types\n",
    "new_column_name = 'responder_category'\n",
    "if (new_column_name in metrics_evaluation_open_world_file_stats_df.columns):\n",
    "    display(metrics_evaluation_open_world_file_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "        'record_count', ascending=False\n",
    "    ).head(5))\n",
    "    raise\n",
    "    metrics_evaluation_open_world_file_stats_df = metrics_evaluation_open_world_file_stats_df.drop(columns=[new_column_name])\n",
    "    print(metrics_evaluation_open_world_file_stats_df.shape)\n",
    "if (new_column_name not in metrics_evaluation_open_world_file_stats_df.columns):\n",
    "    metrics_evaluation_open_world_file_stats_df[new_column_name] = 'EM Resident'\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    print(metrics_evaluation_open_world_file_stats_df.shape) # (43, 3564)\n",
    "\n",
    "display(metrics_evaluation_open_world_file_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56504454-21ac-40dc-a49d-3fe0c58d9afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_columns_set = set(metrics_evaluation_open_world_file_stats_df.columns)\n",
    "intersection_columns = set(['overall_category', 'global_category', 'global_description', 'sub_category', 'sub_description', 'responder_type'])\n",
    "sorted(file_columns_set.intersection(intersection_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c4afdd-e65b-4785-97b4-50dfc25bdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_file_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_file_stats_df.csv\n",
      "(43, 3570)\n",
      "overall_category      1\n",
      "global_category       1\n",
      "global_description    1\n",
      "sub_category          1\n",
      "sub_description       1\n",
      "responder_type        1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_category</th>\n",
       "      <th>global_category</th>\n",
       "      <th>global_description</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_description</th>\n",
       "      <th>responder_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM Resident</th>\n",
       "      <th>DOC</th>\n",
       "      <th>Physicians</th>\n",
       "      <th>DRS</th>\n",
       "      <th>Physician Resident</th>\n",
       "      <th>EM-RES1</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    record_count\n",
       "overall_category global_category global_description sub_category sub_description    responder_type              \n",
       "EM Resident      DOC             Physicians         DRS          Physician Resident EM-RES1                   43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add responder types subgrouping columns\n",
    "groupby_columns = ['overall_category', 'global_category', 'global_description', 'sub_category', 'sub_description', 'responder_type']\n",
    "if any(map(lambda x: x not in metrics_evaluation_open_world_file_stats_df.columns, groupby_columns)):\n",
    "    file_path = '../data/xlsx/Responder_Categories_and_Counts_DPW.xlsx'\n",
    "    dpw_responder_categories_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Get description data frame\n",
    "    mask_series = dpw_responder_categories_df.isna().all(axis='columns')\n",
    "    idx = dpw_responder_categories_df[mask_series].index.min()\n",
    "    where_df = dpw_responder_categories_df.iloc[idx+1:]\n",
    "    \n",
    "    # Get categories data frame\n",
    "    dpw_responder_categories_df = dpw_responder_categories_df.iloc[:idx].dropna(axis='columns', how='all')\n",
    "    dpw_responder_categories_df.columns = ['overall_category', 'responder_type', 'global_category', 'sub_category', 'record_count']\n",
    "    \n",
    "    # Create global description column\n",
    "    columns_list = ['global_category', 'global_description', 'record_count']\n",
    "    df = where_df.iloc[:, 1:4].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    global_description_dict = df.set_index('global_category').global_description.to_dict()\n",
    "    dpw_responder_categories_df['global_description'] = dpw_responder_categories_df.global_category.map(global_description_dict)\n",
    "    \n",
    "    # Create sub description column\n",
    "    columns_list = ['sub_category', 'sub_description', 'record_count']\n",
    "    df = where_df.iloc[:, 5:8].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    sub_description_dict = df.set_index('sub_category').sub_description.to_dict()\n",
    "    dpw_responder_categories_df['sub_description'] = dpw_responder_categories_df.sub_category.map(sub_description_dict)\n",
    "    \n",
    "    # Add columns to file stats data frame\n",
    "    df = dpw_responder_categories_df[groupby_columns].groupby(groupby_columns).size().reset_index(drop=False)\n",
    "    assert not (df[0] != 1).any(), \"You will have a problem with responder types\"\n",
    "    df = df.drop(columns=[0])\n",
    "    assert not (df.groupby('responder_type').size() != 1).any(), \"You have a problem with responder types\"\n",
    "    if 'responder_type' not in metrics_evaluation_open_world_file_stats_df.columns: metrics_evaluation_open_world_file_stats_df['responder_type'] = 'EM-RES1'\n",
    "    for (overall_category, global_category, global_description, sub_category, sub_description, responder_type), _ in df.groupby(groupby_columns):\n",
    "        mask_series = (metrics_evaluation_open_world_file_stats_df.responder_type == responder_type)\n",
    "        for cn in groupby_columns: metrics_evaluation_open_world_file_stats_df.loc[mask_series, cn] = eval(cn)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_file_stats_df=metrics_evaluation_open_world_file_stats_df)\n",
    "    print(metrics_evaluation_open_world_file_stats_df.shape) # (43, 3570)\n",
    "\n",
    "if all(map(lambda x: x in metrics_evaluation_open_world_file_stats_df.columns, groupby_columns)):\n",
    "    print(metrics_evaluation_open_world_file_stats_df[groupby_columns].nunique()) \n",
    "    display(metrics_evaluation_open_world_file_stats_df.groupby(groupby_columns).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "        'record_count', ascending=False\n",
    "    ).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4d2d4e-32b8-4b6a-9b6c-27b0d9dde25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171766, 108)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Delegation', 'Sim2', 'AD_KDMA_Sim', 'Sim1', 'ST_KDMA_Sim', 'Trust', 'AD_ConfFC_Omni_Text', 'Date', 'YrsMilExp', 'AD_ConfFC_Text', 'ST_Del_Text', 'AD_Del_Text', 'MedExp', 'MilitaryExp', 'PropTrust', 'ST_AttribGrp_Text', 'AD_AttribGrp_Text', 'AD_AttribGrp_Sim', 'ST_AttribGrp_Sim', 'ParticipantID', 'ST_KDMA_Text', 'ST_ConfFC_Omni_Text', 'ST_Del_Omni_Text', 'MedRole', 'ST_ConfFC_Text', 'AD_KDMA_Text', 'AD_Del_Omni_Text'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1090/3827501488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mparticipant_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticipant_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_series\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mon_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_stats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticipant_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0msession_uuids_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticipant_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muuid_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmask_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_stats_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_uuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_uuids_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\n",
    "# Try to base the CACI data on the sessions in their spreadsheet\n",
    "from pandas import read_excel\n",
    "\n",
    "logs_df = data_frames_dict['metrics_evaluation_open_world_df']\n",
    "file_stats_df = data_frames_dict['metrics_evaluation_open_world_file_stats_df']\n",
    "scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']\n",
    "print(logs_df.shape)\n",
    "file_path = '../data/xlsx/Metrics_Eval_Participant_data_for_BBAI.xlsx'\n",
    "participant_data_df = read_excel(file_path)\n",
    "uuid_columns = [f'Sim{i}' for i in range(1, 3)]\n",
    "uuid_fn = lambda x: str(x)[:-1]\n",
    "file_stats_uuids = []\n",
    "for participant_id in range(2_024_201, 2_024_223+1):\n",
    "    mask_series = (participant_data_df.ParticipantID == participant_id)\n",
    "    if mask_series.any():\n",
    "        participant_df = participant_data_df[mask_series]\n",
    "        on_columns = set(file_stats_df.columns).intersection(set(participant_df.columns))\n",
    "        display(on_columns); raise\n",
    "        session_uuids_list = participant_df[uuid_columns].applymap(uuid_fn).values.ravel().tolist()\n",
    "        mask_series = file_stats_df.session_uuid.isin(session_uuids_list)\n",
    "        if mask_series.any(): file_stats_uuids.extend(file_stats_df[mask_series].session_uuid.tolist())\n",
    "    else: print(f'You are missing Participant ID #{participant_id} from the Metrics Eval Participant data for BBAI')\n",
    "print(logs_df.shape)\n",
    "# nu.store_objects(metrics_evaluation_open_world_file_stats_df=file_stats_df, verbose=True)\n",
    "# nu.save_data_frames(metrics_evaluation_open_world_file_stats_df=file_stats_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328c08cd-3039-4c7c-bef8-daea10d20550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 22 participants, representing diverse medical roles, completed the ITM scenarios between March 14, 2024 and March 22, 2024. Each participant engaged with two separate open world environments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "# Filter rows with non-null 'Date' values\n",
    "mask_series = ~file_stats_df.Date.isnull()\n",
    "filtered_df = file_stats_df[mask_series]\n",
    "\n",
    "# Get minimum and maximum dates as datetime objects\n",
    "min_date = filtered_df['Date'].min()\n",
    "max_date = filtered_df['Date'].max()\n",
    "\n",
    "# Format the datetime objects for human-readable output\n",
    "min_date_str = datetime.datetime.strptime(min_date, '%m/%d/%Y').strftime('%B %d, %Y')\n",
    "max_date_str = datetime.datetime.strptime(max_date, '%m/%d/%Y').strftime('%B %d, %Y')\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    f'A total of 22 participants, representing diverse medical roles, completed the ITM scenarios between {min_date_str} and {max_date_str}.'\n",
    "    ' Each participant engaged with two separate open world environments.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31706fb9-dc81-410d-832d-008e4804bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3/22/2024'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filtered_df['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67981ab1-67b5-43b7-b51e-8ecad0325690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
