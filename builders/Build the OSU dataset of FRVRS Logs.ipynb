{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f303819c-dc03-46ab-a5fc-d1de4fe42714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88993e1-de14-424b-a21c-ca2308d8ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "from frvrs_utils import FRVRSUtilities\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re\n",
    "import re\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "fu = FRVRSUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc37e1-1f10-499c-a2e0-cfd6cbf5b652",
   "metadata": {},
   "source": [
    "\n",
    "# Build and deidentify the OSU dataset of Simulation Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95c475b-d3d1-4290-964c-8e5d7c7f3ccf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NotebookUtilities' object has no attribute 'data_logs_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m     frvrs_logs_df \u001b[38;5;241m=\u001b[39m nu\u001b[38;5;241m.\u001b[39mload_object(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrvrs_logs_df\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Add the CSVs to the data frame\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     frvrs_logs_df \u001b[38;5;241m=\u001b[39m \u001b[43mfu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatonate_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Remove numerically-named columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     columns_list \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m frvrs_logs_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(x))]\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\itm-analysis-reporting\\builders\\../py\\frvrs_utils.py:2829\u001b[0m, in \u001b[0;36mFRVRSUtilities.concatonate_logs\u001b[1;34m(self, logs_folder)\u001b[0m\n\u001b[0;32m   2824\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnotebook_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotebookUtilities\n\u001b[0;32m   2825\u001b[0m     nu \u001b[38;5;241m=\u001b[39m NotebookUtilities(\n\u001b[0;32m   2826\u001b[0m         data_folder_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_folder,\n\u001b[0;32m   2827\u001b[0m         saves_folder_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaves_folder\n\u001b[0;32m   2828\u001b[0m     )\n\u001b[1;32m-> 2829\u001b[0m     logs_folder \u001b[38;5;241m=\u001b[39m \u001b[43mnu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_logs_folder\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_directory, directories_list, files_list \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(logs_folder):\n\u001b[0;32m   2831\u001b[0m     \n\u001b[0;32m   2832\u001b[0m     \u001b[38;5;66;03m# Create a data frame to store the data for the current subdirectory\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m     sub_directory_df \u001b[38;5;241m=\u001b[39m DataFrame([])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NotebookUtilities' object has no attribute 'data_logs_folder'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all logs into one data frame\n",
    "if nu.pickle_exists('frvrs_logs_df'):\n",
    "    frvrs_logs_df = nu.load_object('frvrs_logs_df')\n",
    "else:\n",
    "    \n",
    "    # Add the CSVs to the data frame\n",
    "    frvrs_logs_df = fu.concatonate_logs()\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in frvrs_logs_df.columns if not re.search(r'\\d+', str(x))]\n",
    "    frvrs_logs_df = frvrs_logs_df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in [\n",
    "        'injury_record_injury_treated_with_wrong_treatment', 'injury_record_injury_treated',\n",
    "        'injury_treated_injury_treated_with_wrong_treatment', 'injury_treated_injury_treated'\n",
    "    ]:\n",
    "        frvrs_logs_df[cn] = frvrs_logs_df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "print(frvrs_logs_df.shape) # (842663, 106)\n",
    "columns_list = [cn for cn in frvrs_logs_df.columns if 'appl' in cn]\n",
    "mask_series = False\n",
    "for cn in columns_list: mask_series |= ~frvrs_logs_df[cn].isnull()\n",
    "df = frvrs_logs_df[mask_series][columns_list]\n",
    "display(df.sample(min(4, df.shape[0])).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e116a-b8a0-4a1d-b132-df6f9e38a1d7",
   "metadata": {},
   "source": [
    "\n",
    "## Check for duplicate file ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7d334-d060-46bf-ab58-9ef5f522c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\n",
    "mask_series = (frvrs_logs_df.groupby('session_uuid').file_name.transform(pd.Series.nunique) > 1)\n",
    "assert frvrs_logs_df[mask_series].shape[0] == 0, \"You have duplicate files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b7e7c-3728-478f-b9e4-2b8c62f872de",
   "metadata": {},
   "source": [
    "\n",
    "## Add new features according to your increasing domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90333cae-adf7-4451-a181-3d4cf5377413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one patient ID column if possible\n",
    "new_column_name = 'patient_id'\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    columns_list= [\n",
    "        'patient_demoted_id', 'patient_record_id', 'injury_record_patient_id', 's_a_l_t_walk_if_can_patient_id',\n",
    "        's_a_l_t_walked_patient_id', 's_a_l_t_wave_if_can_patient_id', 's_a_l_t_waved_patient_id', 'patient_engaged_id',\n",
    "        'pulse_taken_patient_id', 'injury_treated_patient_id', 'tool_applied_patient_id', 'tag_applied_patient_id',\n",
    "        'player_gaze_patient_id'\n",
    "    ]\n",
    "    frvrs_logs_df = nu.modalize_columns(frvrs_logs_df, columns_list, new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620fee1-3032-4f5b-be65-63ef72935c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one location ID column if possible\n",
    "new_column_name = 'location_id'\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    columns_list= [\n",
    "        'teleport_location', 'patient_demoted_position', 'patient_record_position', 'injury_record_injury_injury_locator',\n",
    "        's_a_l_t_walk_if_can_sort_location', 's_a_l_t_walked_sort_location', 's_a_l_t_wave_if_can_sort_location',\n",
    "        's_a_l_t_waved_sort_location', 'patient_engaged_position', 'bag_access_location', 'injury_treated_injury_injury_locator',\n",
    "        'bag_closed_location', 'tag_discarded_location', 'tool_discarded_location', 'player_location_location',\n",
    "        'player_gaze_location'\n",
    "    ]\n",
    "    frvrs_logs_df = nu.modalize_columns(frvrs_logs_df, columns_list, new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a523d-861b-4ac7-b66e-53830521010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one injury ID column if possible\n",
    "new_column_name = 'injury_id'\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    frvrs_logs_df = nu.modalize_columns(frvrs_logs_df, ['injury_record_id', 'injury_treated_id'], new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca86b4a-f8e1-4076-ab21-d45762523aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modalize into one patient sort column if possible\n",
    "new_column_name = 'patient_sort'\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    frvrs_logs_df = nu.modalize_columns(frvrs_logs_df, ['patient_demoted_sort', 'patient_record_sort', 'patient_engaged_sort'], new_column_name)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (829277, 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0d5d9-cabc-4eaa-8e39-fe89a8d4ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a voice capture sentiment score\n",
    "if ('voice_capture_sentiment_score' not in frvrs_logs_df.columns):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    mask_series = frvrs_logs_df.voice_capture_message.isnull()\n",
    "    for row_index, row_series in frvrs_logs_df[~mask_series].iterrows():\n",
    "        voice_capture_message = '\\n' + row_series.voice_capture_message\n",
    "        frvrs_logs_df.loc[row_index, 'voice_capture_sentiment_score'] = sid.polarity_scores(voice_capture_message)['compound']\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f54fd-2e10-438d-a22c-a88dd4738674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mask voice capture PII\n",
    "# OSU screened all of the **VOICE_COMMAND** and **VOICE_CAPTURE** lines and\n",
    "# replaced any names with either Max or Jane, regardless of whether the name was that of the responder.\n",
    "# But, just to make sure...\n",
    "columns_list = ['voice_command_command_description', 'voice_capture_message']\n",
    "if not frvrs_logs_df[columns_list].applymap(lambda x: '[PERSON]' in str(x), na_action='ignore').sum().sum():\n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    \n",
    "    mask_series = frvrs_logs_df.voice_command_command_description.isnull() & frvrs_logs_df.voice_capture_message.isnull()\n",
    "    df = frvrs_logs_df[~mask_series]\n",
    "    def mask_pii(srs):\n",
    "        for idx in columns_list:\n",
    "            new_text = srs[idx]\n",
    "            if str(new_text) != 'nan':\n",
    "                doc = nlp(new_text)\n",
    "                for entity in doc.ents:\n",
    "                    if entity.label_ == 'PERSON':\n",
    "                        new_text = re.sub('\\\\b' + entity.text + '\\\\b', '[PERSON]', new_text)\n",
    "                srs[idx] = new_text\n",
    "    \n",
    "        return srs\n",
    "    \n",
    "    for row_index, row_series in df.apply(mask_pii, axis='columns')[columns_list].iterrows():\n",
    "        for column_name, column_value in row_series.items():\n",
    "            if str(column_value) != 'nan':\n",
    "                frvrs_logs_df.loc[row_index, column_name] = column_value\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd04e1d-fec5-42fd-9118-e59ac7832020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Any runs longer than that 16 minutes are probably an instance\n",
    "# of someone taking off the headset and setting it on the ground.\n",
    "# 1 second = 1,000 milliseconds; 1 minute = 60 seconds\n",
    "new_column_name = 'is_scene_aborted'\n",
    "if (new_column_name in frvrs_logs_df.columns): frvrs_logs_df = frvrs_logs_df.drop(columns=new_column_name)\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    frvrs_logs_df[new_column_name] = False\n",
    "    for (session_uuid, scene_index), scene_df in frvrs_logs_df.groupby(fu.scene_groupby_columns):\n",
    "        mask_series = True\n",
    "        for cn in fu.scene_groupby_columns: mask_series &= (frvrs_logs_df[cn] == eval(cn))\n",
    "        frvrs_logs_df.loc[mask_series, new_column_name] = fu.get_is_scene_aborted(scene_df)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 111)\n",
    "    display(frvrs_logs_df.groupby('is_scene_aborted').size().to_frame().rename(columns={0: 'count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f23ce-3849-4f58-99f3-093a176415e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if all the patient IDs in any run are some variant of Mike and designate those runs as \"Orientation\"\n",
    "if ('scene_type' not in frvrs_logs_df.columns): frvrs_logs_df['scene_type'] = 'Triage'\n",
    "column_value = 'Orientation'\n",
    "if (column_value not in frvrs_logs_df.scene_type.unique()):\n",
    "    \n",
    "    # Filter out those files from the dataset and mark them\n",
    "    base_mask_series = frvrs_logs_df.groupby(fu.scene_groupby_columns).patient_id.transform(lambda srs: all(srs.str.lower().str.contains('mike')))\n",
    "    frvrs_logs_df.loc[base_mask_series, 'scene_type'] = column_value\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9a04b-a9b2-4bef-aedd-df9b112e199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a sample with a clear count of responders\n",
    "new_column_name = 'is_a_one_triage_file'\n",
    "if (new_column_name not in frvrs_logs_df.columns):\n",
    "    frvrs_logs_df[new_column_name] = False\n",
    "    for file_name in frvrs_logs_df.file_name.unique():\n",
    "        is_a_one_triage_file = fu.get_is_a_one_triage_file(frvrs_logs_df, file_name)\n",
    "        mask_series = (frvrs_logs_df.file_name == file_name)\n",
    "        frvrs_logs_df.loc[mask_series, new_column_name] = is_a_one_triage_file\n",
    "    \n",
    "    nu.store_objects(frvrs_logs_df=frvrs_logs_df)\n",
    "    print(frvrs_logs_df.shape) # (842663, 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50d342-667d-447f-862c-8272c6cb9fcb",
   "metadata": {},
   "source": [
    "\n",
    "## Remove training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28122856-4de4-4815-ac4f-c0294dc2e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DaveBabbitt\\Documents\\GitHub\\itm-analysis-reporting\\data\\logs\\All CSV files renamed by date\\Notes.docx\n",
      "\n",
      "DCEMS 11.22 – 12.22 – OK\n",
      "Madison Township 4.18.23 and 4.20.23 – Training and Triage are combined.\n",
      "Union County Marysville 04.25.23 - Training and Triage are combined.\n",
      "Disaster Day 3.14.23 and 3.15.23 are almost all combined.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import docx\n",
    "\n",
    "logs_folder = nu.data_logs_folder\n",
    "for sub_directory, directories_list, files_list in os.walk(logs_folder):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith('.docx'):\n",
    "            file_path = os.path.join(sub_directory, file_name)\n",
    "            print(file_path)\n",
    "            doc = docx.Document(file_path)\n",
    "            text = ''\n",
    "            for paragraph in doc.paragraphs: text += '\\n' + paragraph.text\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d722dd-552a-488e-8593-3fbcf4d5ab99",
   "metadata": {},
   "source": [
    "\n",
    "## We need to add a _responder_type_:\n",
    "\n",
    "EMT = EMT Basic\n",
    "\n",
    "AEMT = EMT Advanced or Intermediate\n",
    "\n",
    "MEDIC = Paramedic\n",
    "\n",
    "STDNT = Any Medical Student\n",
    "\n",
    "RSDNT = Any Resident\n",
    "\n",
    "FELO = Any EM Fellow\n",
    "\n",
    "ATEND = Any Attending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916f4d3b-c10f-4013-9d3b-8429a8b50b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the custom categorical orders\n",
    "responder_types = ['EMT', 'AEMT', 'MEDIC', 'STDNT', 'RSDNT', 'FELO', 'ATEND']\n",
    "responder_types_category_order = pd.CategoricalDtype(categories=responder_types, ordered=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.9)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
