{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c1cf72-c722-4a6f-8396-9882637d4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ca045c-fbb0-4823-a0af-8098c170e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from frvrs_utils import FRVRSUtilities\n",
    "from notebook_utils import NotebookUtilities\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "fu = FRVRSUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae9e04-f3d2-490c-b79a-2d11d17bcf51",
   "metadata": {},
   "source": [
    "\n",
    "# Rasch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003c72ad-4246-4470-b92c-dc0bfa20e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/frvrs_logs_df.pkl.\n",
      "Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)\n",
      "No pickle exists for frvrs_logs_df - attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/frvrs_logs_df.csv.\n",
      "(829116, 114)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frvrs_logs_df = nu.load_data_frames(frvrs_logs_df='frvrs_logs_df')['frvrs_logs_df']\n",
    "print(frvrs_logs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c65634-4c76-477b-ac59-e20ec59026f2",
   "metadata": {},
   "source": [
    "\n",
    "## Calculate item logits\n",
    "<p>In Rasch analysis, item logits, also known as item difficulty, represent the location of an item on the latent variable measured by the instrument. They are calculated based on the observed responses of participants to the item. Here's how to compute item logits for a task with 0-1 scores:</p>\n",
    "<p><strong>1. Calculate the probability of a correct response:</strong></p>\n",
    "<ul>\n",
    "    <li>For each participant, determine their score on the task (0 or 1).</li>\n",
    "    <li>Count the total number of correct responses across all participants.</li>\n",
    "    <li>Divide the number of correct responses by the total number of participants. This gives you the probability (P) of a correct response for the task.</li>\n",
    "</ul>\n",
    "<p><strong>2. Convert the probability to log-odds (logit):</strong></p>\n",
    "<ul>\n",
    "    <li>Use the natural logarithm (ln) function to calculate the log-odds of a correct response:</li>\n",
    "</ul>\n",
    "<quote>\n",
    "    <pre><code>Logit = ln(P/(1-P))</code></pre>\n",
    "</quote>\n",
    "<p><strong>3. Adjust for item calibration:</strong></p>\n",
    "<ul>\n",
    "    <li>In Rasch analysis, item logits are typically estimated iteratively within a calibration process. This process considers the responses to all items and participants to adjust the initial item logit estimates.</li>\n",
    "    <li>Software programs such as Winsteps, RUMM2030, and Facets can be used to perform Rasch analysis and provide calibrated item logit estimates.</li>\n",
    "</ul>\n",
    "<p><strong>Additional Considerations:</strong></p>\n",
    "<ul>\n",
    "    <li>Item difficulty is interpreted relative to the ability of the participants. A positive logit value indicates that the item is difficult, requiring a higher ability level to answer correctly. Conversely, a negative logit value indicates that the item is easier, requiring a lower ability level to answer correctly.</li>\n",
    "    <li>The precision of the item logit estimate depends on several factors, including the sample size and the distribution of participant abilities. Larger sample sizes and a wider range of abilities will generally lead to more precise estimates.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46aba3e7-c990-47c3-aff2-6c9dcdf13154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# For each score, determine their scores on each task (0 or 1)\n",
    "base_mask_series = (frvrs_logs_df.scene_type == 'Triage') & (frvrs_logs_df.is_scene_aborted == False) & (frvrs_logs_df.is_a_one_triage_file == True)\n",
    "gb = frvrs_logs_df[base_mask_series].sort_values(['action_tick']).groupby(fu.scene_groupby_columns)\n",
    "rows_list = []\n",
    "for (session_uuid, scene_id), scene_df in gb:\n",
    "    is_stills_visited_first = fu.get_stills_value(scene_df)\n",
    "    is_walk_command_issued = fu.get_walk_value(scene_df)\n",
    "    is_walkers_visited_last = fu.get_walkers_value(scene_df)\n",
    "    is_wave_command_issued = fu.get_wave_value(scene_df)\n",
    "    for patient_id, patient_df in scene_df.groupby('patient_id'):\n",
    "        is_pulse_taken = fu.get_pulse_value(patient_df)\n",
    "        is_tag_correct = fu.get_tag_value(patient_df)\n",
    "        for injury_id, injury_df in patient_df.groupby('injury_id'):\n",
    "            row_dict = {}\n",
    "            for cn in fu.patient_groupby_columns: row_dict[cn] = eval(cn)\n",
    "            row_dict['is_stills_visited_first'] = is_stills_visited_first\n",
    "            row_dict['is_walk_command_issued'] = is_walk_command_issued\n",
    "            row_dict['is_walkers_visited_last'] = is_walkers_visited_last\n",
    "            row_dict['is_wave_command_issued'] = is_wave_command_issued\n",
    "            row_dict['is_injury_treated'] = fu.get_treatment_value(patient_df, injury_id)\n",
    "            row_dict['is_pulse_taken'] = is_pulse_taken\n",
    "            row_dict['is_tag_correct'] = is_tag_correct\n",
    "            rows_list.append(row_dict)\n",
    "item_logits_df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c504050c-d4b3-4127-bde4-1f6759566bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(item_logits_df.is_tag_correct.sum())\n",
    "assert item_logits_df.applymap(lambda x: str(x) in ['None', 'nan']).sum().sum() == 0, \"You have nulls in your data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409b21f2-c771-4923-9aa6-e011ba352b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the total number of correct responses across all scenes\n",
    "srs = item_logits_df.sum()\n",
    "correct_stills_count = srs.is_stills_visited_first\n",
    "correct_walk_count = srs.is_walk_command_issued\n",
    "correct_walkers_count = srs.is_walkers_visited_last\n",
    "correct_wave_count = srs.is_wave_command_issued\n",
    "correct_injury_count = srs.is_injury_treated\n",
    "correct_pulse_count = srs.is_pulse_taken\n",
    "correct_tag_count = srs.is_tag_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87a4724-184e-41a1-bd75-0fb1d7378097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Divide the number of correct responses by the total number of scenes\n",
    "# This gives you the probability (P) of a correct response for each task\n",
    "scene_count = item_logits_df.shape[0]\n",
    "correct_stills_probability = correct_stills_count / scene_count\n",
    "correct_walk_probability = correct_walk_count / scene_count\n",
    "correct_walkers_probability = correct_walkers_count / scene_count\n",
    "correct_wave_probability = correct_wave_count / scene_count\n",
    "correct_injury_probability = correct_injury_count / scene_count\n",
    "correct_pulse_probability = correct_pulse_count / scene_count\n",
    "correct_tag_probability = correct_tag_count / scene_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fa228c-ba13-4ce0-b581-81245e03891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the natural logarithm (ln) function to calculate the log-odds of a correct response\n",
    "import math\n",
    "\n",
    "try: correct_stills_logodds = math.log(correct_stills_probability / (1 - correct_stills_probability))\n",
    "except: correct_stills_logodds = np.nan\n",
    "try: correct_walk_logodds = math.log(correct_walk_probability / (1 - correct_walk_probability))\n",
    "except: correct_walk_logodds = np.nan\n",
    "try: correct_walkers_logodds = math.log(correct_walkers_probability / (1 - correct_walkers_probability))\n",
    "except: correct_walkers_logodds = np.nan\n",
    "try: correct_wave_logodds = math.log(correct_wave_probability / (1 - correct_wave_probability))\n",
    "except: correct_wave_logodds = np.nan\n",
    "try: correct_injury_logodds = math.log(correct_injury_probability / (1 - correct_injury_probability))\n",
    "except: correct_injury_logodds = np.nan\n",
    "try: correct_pulse_logodds = math.log(correct_pulse_probability / (1 - correct_pulse_probability))\n",
    "except: correct_pulse_logodds = np.nan\n",
    "try: correct_tag_logodds = math.log(correct_tag_probability / (1 - correct_tag_probability))\n",
    "except: correct_tag_logodds = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b67c19-4342-4297-b48a-5d904f57ca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log-odds of correctly visiting still patients (first): -1.307552889804326\n",
      "Log-odds of issuing the \"walk\" command: 3.385449024694017\n",
      "Log-odds of correctly visiting walking patients (last): -0.4027851211222216\n",
      "Log-odds of issuing the \"wave\" command: 1.4869252322225146\n",
      "Log-odds of correctly treating an injury: -0.3140038792048232\n",
      "Log-odds of taking a pulse: 0.86385487698838\n",
      "Log-odds of correctly tagging a patient: 1.089858220508195\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''\n",
    "Log-odds of correctly visiting still patients (first): {correct_stills_logodds}\n",
    "Log-odds of issuing the \"walk\" command: {correct_walk_logodds}\n",
    "Log-odds of correctly visiting walking patients (last): {correct_walkers_logodds}\n",
    "Log-odds of issuing the \"wave\" command: {correct_wave_logodds}\n",
    "Log-odds of correctly treating an injury: {correct_injury_logodds}\n",
    "Log-odds of taking a pulse: {correct_pulse_logodds}\n",
    "Log-odds of correctly tagging a patient: {correct_tag_logodds}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a94d46-c688-40e8-b244-804689a24727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Rasch analysis, if the shape of item_logits was (7,) and the shape of scores was (6839, 7), what would we expect the shape of scene_estimates to be in this iterative calibration process?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define convergence threshold\n",
    "threshold = 0.001\n",
    "\n",
    "# Initialize item logits and scores\n",
    "item_logits = np.array([\n",
    "    correct_stills_logodds, correct_walk_logodds, correct_walkers_logodds, correct_wave_logodds, correct_injury_logodds, correct_pulse_logodds, correct_tag_logodds\n",
    "])\n",
    "columns_list = [\n",
    "    'is_stills_visited_first', 'is_walk_command_issued', 'is_walkers_visited_last', 'is_wave_command_issued', 'is_injury_treated', 'is_pulse_taken', 'is_tag_correct'\n",
    "]\n",
    "assert len(item_logits) == len(columns_list), 'The item logits need to be the same count as the number of columns in scores'\n",
    "df = item_logits_df[columns_list]\n",
    "scores = df.values\n",
    "assert df.applymap(lambda x: x not in [0, 1]).sum().sum() == 0, 'You have non-Bernoulli data'\n",
    "\n",
    "# Define the number of iterations\n",
    "iterations = 100\n",
    "\n",
    "print(\n",
    "    f'In Rasch analysis, if the shape of item_logits was {item_logits.shape} and the shape of scores was {scores.shape},'\n",
    "    ' what would we expect the shape of scene_estimates to be in this iterative calibration process?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec4317bd-6f60-4e1c-b6e2-264b3cd5a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_data(item_logits, scores, verbose=False):\n",
    "    \"\"\"\n",
    "    Estimate scene characteristics using an iterative proportional fitting (IPF)\n",
    "    algorithm for the Rasch model.\n",
    "\n",
    "    Parameters:\n",
    "        item_logits (numpy.ndarray): An array of item logits representing the\n",
    "                                     log-odds of scoring on the item.\n",
    "        scores (numpy.ndarray): A binary matrix where each row represents an injury-\n",
    "                                patient-scene and each column an item, indicating\n",
    "                                the pass-fail score the injury got on the test item.\n",
    "        verbose (bool, optional): If True, print intermediate results for debugging.\n",
    "                                  Default is False.\n",
    "\n",
    "    Returns:\n",
    "        scene_estimates (numpy.ndarray): An array containing scene estimates based\n",
    "                                         on the Rasch model.\n",
    "        updated_item_logits (numpy.ndarray): Updated item logits after the\n",
    "                                             iteration.\n",
    "\n",
    "    Note:\n",
    "        The Rasch model is typically estimated using maximum likelihood estimation\n",
    "        (MLE) methods, which involve iteratively updating the item parameters and\n",
    "        the person abilities until convergence is achieved. The algorithm used\n",
    "        here is a type of iterative proportional fitting (IPF) algorithm, which is\n",
    "        a type of MLE algorithm that is commonly used to estimate IRT models like\n",
    "        the Rasch model. The IPF algorithm is similar to the EM algorithm in that\n",
    "        it involves iteratively updating the item parameters and the person\n",
    "        abilities until convergence is achieved. However, the IPF algorithm is\n",
    "        simpler than the EM algorithm because it does not require the calculation\n",
    "        of expected sufficient statistics.\n",
    "    \"\"\"\n",
    "    if verbose: print('\\nitem_logits', item_logits.shape, '\\n', item_logits)\n",
    "    if verbose: print('\\nscores', scores.shape, '\\n', scores)\n",
    "    \n",
    "    # Calculate the expected scores for each item\n",
    "    expected_scores = 1 / (1 + np.exp(-item_logits))\n",
    "    if verbose: print('\\nexpected_scores', expected_scores.shape, '\\n', expected_scores)\n",
    "    \n",
    "    # Calculate the observed scores for each item\n",
    "    observed_scores = scores.mean(axis=0)\n",
    "    if verbose: print('\\nobserved_scores', observed_scores.shape, '\\n', observed_scores)\n",
    "    \n",
    "    # Calculate the difference between the observed and expected scores for each item\n",
    "    score_diffs = observed_scores - expected_scores\n",
    "    if verbose: print('\\nscore_diffs', score_diffs.shape, '\\n', score_diffs)\n",
    "    \n",
    "    # Calculate the sum of the score differences for each item\n",
    "    score_sums = score_diffs.sum()\n",
    "    if verbose: print('\\nscore_sums', score_sums.shape, '\\n', score_sums)\n",
    "    \n",
    "    # Update the item logits for the next iteration\n",
    "    updated_item_logits = item_logits + score_sums\n",
    "    if verbose: print('\\nupdated_item_logits', updated_item_logits.shape, '\\n', updated_item_logits)\n",
    "    \n",
    "    # Calculate the scene estimates using the updated item logits\n",
    "    scene_estimates = np.sum(scores - 0.5, axis=1) - np.sum((expected_scores - 0.5).reshape(1, -1), axis=1)\n",
    "    if verbose: print('\\nscene_estimates', scene_estimates.shape, '\\n', scene_estimates)\n",
    "    \n",
    "    return scene_estimates, updated_item_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a144acb0-8500-4edb-a3c4-3ed23f78abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "item_logits (7,) \n",
      " [-1.30755289  3.38544902 -0.40278512  1.48692523 -0.31400388  0.86385488\n",
      "  1.08985822]\n",
      "\n",
      "scores (6839, 7) \n",
      " [[0 1 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 1 0]\n",
      " [0 1 0 ... 0 1 0]\n",
      " ...\n",
      " [0 1 0 ... 1 0 1]\n",
      " [0 1 0 ... 1 0 0]\n",
      " [0 1 0 ... 1 0 0]]\n",
      "\n",
      "expected_scores (7,) \n",
      " [0.21289662 0.96724667 0.40064337 0.81561632 0.42213774 0.70346542\n",
      " 0.74835502]\n",
      "\n",
      "observed_scores (7,) \n",
      " [0.21289662 0.96724667 0.40064337 0.81561632 0.42213774 0.70346542\n",
      " 0.74835502]\n",
      "\n",
      "score_diffs (7,) \n",
      " [ 2.77555756e-17  0.00000000e+00  0.00000000e+00 -1.11022302e-16\n",
      " -5.55111512e-17  0.00000000e+00  0.00000000e+00]\n",
      "\n",
      "score_sums () \n",
      " -1.3877787807814457e-16\n",
      "\n",
      "updated_item_logits (7,) \n",
      " [-1.30755289  3.38544902 -0.40278512  1.48692523 -0.31400388  0.86385488\n",
      "  1.08985822]\n",
      "\n",
      "scene_estimates (6839,) \n",
      " [-1.27036116 -1.27036116 -1.27036116 ... -0.27036116 -1.27036116\n",
      " -1.27036116]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "verbose = True\n",
    "for _ in range(iterations):\n",
    "    \n",
    "    # Perform Rasch analysis using the current item logits\n",
    "    scene_estimates, updated_item_logits = analyze_data(item_logits, scores, verbose=verbose)\n",
    "    verbose = False\n",
    "    assert scene_estimates.shape == (scores.shape[0],), 'The estimated ability of each scene has the wrong shape'\n",
    "    assert updated_item_logits.shape == item_logits.shape, 'The shape of the new difficulty levels for each item after the current iteration is wrong'\n",
    "    \n",
    "    # Check for convergence\n",
    "    if max(abs(updated_item_logits - item_logits)) <= threshold: break\n",
    "    \n",
    "    # Update item logits for the next iteration\n",
    "    item_logits = updated_item_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db200d81-a9c8-4d9d-93cd-c8c10f88b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log-odds of correctly visiting still patients (first): -1.3075528898043263\n",
      "Log-odds of issuing the \"walk\" command: 3.385449024694017\n",
      "Log-odds of correctly visiting walking patients (last): -0.40278512112222176\n",
      "Log-odds of issuing the \"wave\" command: 1.4869252322225144\n",
      "Log-odds of correctly treating an injury: -0.3140038792048233\n",
      "Log-odds of taking a pulse: 0.8638548769883799\n",
      "Log-odds of correctly tagging a patient: 1.0898582205081948\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''\n",
    "Log-odds of correctly visiting still patients (first): {updated_item_logits[0]}\n",
    "Log-odds of issuing the \"walk\" command: {updated_item_logits[1]}\n",
    "Log-odds of correctly visiting walking patients (last): {updated_item_logits[2]}\n",
    "Log-odds of issuing the \"wave\" command: {updated_item_logits[3]}\n",
    "Log-odds of correctly treating an injury: {updated_item_logits[4]}\n",
    "Log-odds of taking a pulse: {updated_item_logits[5]}\n",
    "Log-odds of correctly tagging a patient: {updated_item_logits[6]}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "783e4ac4-89d7-4e8a-8d1b-b0752bb8ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the Fisher information\n",
    "correct_stills_fisher = correct_stills_probability * (1 - correct_stills_probability)\n",
    "correct_walk_fisher = correct_walk_probability * (1 - correct_walk_probability)\n",
    "correct_walkers_fisher = correct_walkers_probability * (1 - correct_walkers_probability)\n",
    "correct_wave_fisher = correct_wave_probability * (1 - correct_wave_probability)\n",
    "correct_injury_fisher = correct_injury_probability * (1 - correct_injury_probability)\n",
    "correct_pulse_fisher = correct_pulse_probability * (1 - correct_pulse_probability)\n",
    "correct_tag_fisher = correct_tag_probability * (1 - correct_tag_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b23924-421c-4bf4-a100-33d5c5cd50cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the model standard error for item measures\n",
    "correct_stills_mse = 1 / math.sqrt(correct_stills_fisher)\n",
    "correct_walk_mse = 1 / math.sqrt(correct_walk_fisher)\n",
    "correct_walkers_mse = 1 / math.sqrt(correct_walkers_fisher)\n",
    "correct_wave_mse = 1 / math.sqrt(correct_wave_fisher)\n",
    "correct_injury_mse = 1 / math.sqrt(correct_injury_fisher)\n",
    "correct_pulse_mse = 1 / math.sqrt(correct_pulse_fisher)\n",
    "correct_tag_mse = 1 / math.sqrt(correct_tag_fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b4c584-85ae-4989-b1ca-fd4e81a98463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "correct_stills_mse = 2.241692719274822\n",
      "correct_walk_mse = 5.618283762312336\n",
      "correct_walkers_mse = 2.015443147981806\n",
      "correct_wave_mse = 2.5786702240404464\n",
      "correct_injury_mse = 2.024700284262668\n",
      "correct_pulse_mse = 2.1894798361849324\n",
      "correct_tag_mse = 2.304369019293232\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'''\n",
    "correct_stills_mse = {correct_stills_mse}\n",
    "correct_walk_mse = {correct_walk_mse}\n",
    "correct_walkers_mse = {correct_walkers_mse}\n",
    "correct_wave_mse = {correct_wave_mse}\n",
    "correct_injury_mse = {correct_injury_mse}\n",
    "correct_pulse_mse = {correct_pulse_mse}\n",
    "correct_tag_mse = {correct_tag_mse}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1093e60-fdd0-4a7c-85f8-dba9da1347ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.13)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
