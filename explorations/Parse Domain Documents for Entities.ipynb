{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51ab3c6-9bc9-4299-86d6-64763b66e8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c96aaf-34eb-4e78-b477-d2e6bd721e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "# from edstan_data import EdstanData\n",
    "from frvrs_utils import FRVRSUtilities\n",
    "from notebook_utils import NotebookUtilities\n",
    "from pandas import DataFrame\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "nu = NotebookUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "fu = FRVRSUtilities(\n",
    "    data_folder_path=osp.abspath('../data'),\n",
    "    saves_folder_path=osp.abspath('../saves')\n",
    ")\n",
    "from scrape_utils import WebScrapingUtilities\n",
    "wsu = WebScrapingUtilities(\n",
    "    s=nu,\n",
    "    secrets_json_path=os.path.abspath(os.path.join(nu.data_folder, 'secrets', 'bbai_secrets.json'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ffe8e-6573-470f-aef5-348522a0de15",
   "metadata": {},
   "source": [
    "\n",
    "# Parse Domain Documents for Entities\n",
    "\n",
    "Downloaded all documents from https://nextcentury.atlassian.net/wiki/spaces/ITMC/pages/2991849482/Domain+Documents and converted them all to PDF files and stored them in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea43e5c-ac11-4453-accc-78c7f84e4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053cef1-4571-4abd-9868-2b0de4bf37de",
   "metadata": {},
   "source": [
    "\n",
    "## Option 1: Use a Hugging Face NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7aa80a7-6e36-430e-8dd9-d6fbd67f3c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoPrevNextNodePostprocessor', 'CohereRerank', 'EmbeddingRecencyPostprocessor', 'FixedRecencyPostprocessor', 'KeywordNodePostprocessor', 'LLMRerank', 'LongContextReorder', 'LongLLMLinguaPostprocessor', 'MetadataReplacementPostProcessor', 'NERPIINodePostprocessor', 'PIINodePostprocessor', 'PrevNextNodePostprocessor', 'SentenceEmbeddingOptimizer', 'SentenceTransformerRerank', 'SimilarityPostprocessor', 'TimeWeightedPostprocessor', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'cohere_rerank', 'llm_rerank', 'longllmlingua', 'metadata_replacement', 'node', 'node_recency', 'optimizer', 'pii', 'sbert_rerank', 'types']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from llama_index import postprocessor\n",
    "\n",
    "dir(postprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003f66f0-f67f-47f2-88eb-b2bbb6d33791",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.postprocessor import NERPIINodePostprocessor\n",
    "\n",
    "# Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization\n",
    "os.environ['OPENAI_API_KEY'] = wsu.secrets_json['OPENAI_API_KEY']\n",
    "service_context = ServiceContext.from_defaults()\n",
    "processor = NERPIINodePostprocessor(service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e474dff1-2f02-4ab6-b5f6-61b8eda7af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load documents\n",
    "import PyPDF2\n",
    "from llama_index.schema import TextNode\n",
    "\n",
    "pdf_folder = '../data/Domain_Knowledge'\n",
    "with open(osp.join(pdf_folder, 'DoDTR-Data-Dictionary-External.pdf'), 'rb') as file:\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    text = ''\n",
    "    for page_number in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_number]\n",
    "        text += page.extract_text()\n",
    "node = TextNode(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8819f-70fe-428c-9180-45d726608c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.postprocessor import (\n",
    "    PIINodePostprocessor,\n",
    "    NERPIINodePostprocessor,\n",
    ")\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index import ServiceContext, Document, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76c995c-57ee-4d1b-a771-6626ef93e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea7b1566d944d77a009e0b2c2a9bfa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bf6952b7574fae8a87de56f3bebaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43905af0e5ab42b1b10b0affd0400417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f635d66ae804fd0a771ebb16000d4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from llama_index.schema import NodeWithScore\n",
    "\n",
    "new_nodes = processor.postprocess_nodes([NodeWithScore(node=node)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "075d45dc-a226-4ba7-8c8a-d9dd536f8560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[ORG_3]': 'DOD TRAUM', '[ORG_124]': 'Joint T', '[MISC_131]': '##ra', '[ORG_133]': '##uma System', '[ORG_145]': 'JTS', '[ORG_157]': 'Department of Defense', '[ORG_180]': 'DoD', '[MISC_253]': 'Joint Trauma System', '[MISC_297]': 'Sailor', '[MISC_305]': 'Marine', '[MISC_316]': 'Air', '[ORG_478]': 'JTS', '[ORG_654]': 'JTS', '[MISC_751]': 'M', '[ORG_799]': 'DoD T', '[MISC_804]': '##rauma', '[ORG_810]': 'Registry', '[ORG_821]': 'DoDTR', '[ORG_936]': 'DoD', '[ORG_1109]': 'DoDTR', '[MISC_1151]': 'Global War on Terror', '[MISC_1174]': 'G', '[MISC_1177]': '##T', '[ORG_1335]': 'Combat', '[MISC_1342]': 'Trauma', '[ORG_1349]': 'Registry', '[ORG_1359]': 'CTR', '[ORG_1397]': 'Center for AMEDD Strategic Studies', '[ORG_1433]': 'CASS', '[LOC_1579]': 'Landstuhl Regional Medical Center', '[ORG_1615]': 'LRMC', '[LOC_1624]': 'Germany', '[ORG_1687]': 'Army', '[ORG_1789]': 'Joint', '[ORG_1804]': '##ra', '[ORG_1810]': 'System', '[ORG_1818]': 'J', '[ORG_1821]': '##S', '[ORG_1846]': 'Joint', '[ORG_1853]': '##ra', '[ORG_1859]': 'System', '[ORG_1867]': 'J', '[ORG_1887]': 'J', '[MISC_1888]': '##TT', '[ORG_1890]': '##S', '[ORG_1923]': 'Joint', '[ORG_1938]': '##ra', '[ORG_1944]': 'Registry', '[ORG_1955]': 'J', '[MISC_1956]': '##TT', '[ORG_2013]': 'J', '[MISC_2014]': '##TT', '[ORG_2041]': 'National', '[ORG_2051]': '##ra', '[ORG_2070]': '##DB'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get mapping in metadata\n",
    "new_nodes[0].node.metadata[\"__pii_node_info__\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf35e4f-a9d3-4d13-9fc5-7c716444231b",
   "metadata": {},
   "source": [
    "\n",
    "## Option 2: Use SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd0675e-15a2-4582-ad82-b1b8f16c6937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'PERSON', 'text': 'Barack Obama', 'start_pos': 0, 'end_pos': 12}, {'type': 'ORDINAL', 'text': '44th', 'start_pos': 21, 'end_pos': 25}, {'type': 'GPE', 'text': 'the United States', 'start_pos': 39, 'end_pos': 56}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "# Example usage\n",
    "text = 'Barack Obama was the 44th President of the United States.'\n",
    "\n",
    "# Load the spaCy model\n",
    "try: nlp = spacy.load('en_core_web_sm')\n",
    "except OSError as e:\n",
    "    print(str(e).strip())\n",
    "    command_str = f'{sys.executable} -m spacy download en_core_web_sm --quiet'\n",
    "    print(command_str)\n",
    "    !{command_str}\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    # for fn in dir(ent):\n",
    "    #     value = eval(f'ent.{fn}')\n",
    "    #     print(f'{fn}: {value}')\n",
    "    entities.append({\n",
    "        'type': ent.label_,\n",
    "        'text': ent.text, # Or lemma_, orth_, text_with_ws\n",
    "        'start_pos': ent.start_char, # Or start\n",
    "        'end_pos': ent.end_char # Or end\n",
    "    })\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb19cd-6c5c-43f5-9280-a8ec6853af7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (Python 3.10.13)",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
