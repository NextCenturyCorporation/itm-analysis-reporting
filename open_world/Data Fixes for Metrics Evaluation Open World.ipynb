{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d497083-b501-4f84-bca7-d691eded680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up the notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16caa025-311a-4cf5-a53a-7258640a8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load libraries\n",
    "from FRVRS import nu, fu\n",
    "import os.path as osp\n",
    "from pandas import DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe874fd-4fdb-47b2-aec5-0c09e07cc1e4",
   "metadata": {},
   "source": [
    "\n",
    "# Data Fixes for Metrics Evaluation Open World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8efbc6-3281-42a4-8c8e-4fe8062b7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_df='', metrics_evaluation_open_world_json_stats_df='', metrics_evaluation_open_world_scene_stats_df=''\n",
    ")\n",
    "metrics_evaluation_open_world_df = data_frames_dict['metrics_evaluation_open_world_df']\n",
    "metrics_evaluation_open_world_json_stats_df = data_frames_dict['metrics_evaluation_open_world_json_stats_df']\n",
    "metrics_evaluation_open_world_scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df161d2-7b15-40a4-b0dd-e07e4d7359ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scene_columns_set = set(metrics_evaluation_open_world_scene_stats_df.columns)\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "intersection_columns = set(['is_scene_aborted'])\n",
    "\n",
    "# Drop the logs columns already recorded in the scene stats data frames\n",
    "drop_columns = sorted(scene_columns_set.intersection(logs_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_df = metrics_evaluation_open_world_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_df.shape) # (171766, 107)\n",
    "    nu.store_objects(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fedcd61f-86f0-4f26-a82d-5b78998ceb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "file_columns_set = set(metrics_evaluation_open_world_json_stats_df.columns)\n",
    "intersection_columns = set(['logger_version', 'is_scene_aborted'])\n",
    "\n",
    "# Drop the logs columns already recorded in the JSON and scene stats data frames\n",
    "drop_columns = list(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_df = metrics_evaluation_open_world_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_df.shape) # (171766, 124)\n",
    "    nu.store_objects(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_df=metrics_evaluation_open_world_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4385ef6-f73f-4ca5-a108-6c430acf3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bag_access_location', 'injury_record_injury_treated', 'injury_record_injury_treated_with_wrong_treatment', 'patient_demoted_health_level', 'patient_demoted_health_time_remaining', 'patient_engaged_health_level', 'patient_record_health_level', 'player_location_left_hand_location', 'player_location_right_hand_location', 'voice_capture_command_description']\n",
      "(43, 3561)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logs_columns_set = set(metrics_evaluation_open_world_df.columns)\n",
    "file_columns_set = set(metrics_evaluation_open_world_json_stats_df.columns)\n",
    "intersection_columns = set([\n",
    "    'injury_record_injury_treated', 'injury_record_injury_treated_with_wrong_treatment', 'patient_demoted_health_level', 'patient_demoted_health_time_remaining',\n",
    "    'patient_demoted_hearing', 'patient_hearing', 'patient_record_health_level', 'patient_record_hearing', 'player_location_left_hand_location',\n",
    "    'player_location_right_hand_location', 'bag_access_location', 'patient_engaged_health_level', 'voice_capture_command_description'\n",
    "])\n",
    "\n",
    "# Drop the JSON Stats columns that came with the process but are covered well enough in the logs data frame and add no value here\n",
    "drop_columns = sorted(logs_columns_set.intersection(file_columns_set).intersection(intersection_columns))\n",
    "print(drop_columns)\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3589)\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dacb6c3-2baa-421c-b1c9-bb21fdb2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_columns_set = set(metrics_evaluation_open_world_json_stats_df.columns)\n",
    "scene_columns_set = set(metrics_evaluation_open_world_scene_stats_df.columns)\n",
    "intersection_columns = set(['logger_version'])\n",
    "\n",
    "# Drop the scene columns already recorded in the JSON Stats data frames\n",
    "drop_columns = sorted(file_columns_set.intersection(scene_columns_set).intersection(intersection_columns))\n",
    "if drop_columns:\n",
    "    metrics_evaluation_open_world_scene_stats_df = metrics_evaluation_open_world_scene_stats_df.drop(columns=drop_columns)\n",
    "    print(metrics_evaluation_open_world_scene_stats_df.shape) # (76, 48)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8fe582d-0a3f-40bf-8d7d-9448334c0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the JSON Stats data frame\n",
    "subset_columns = ['session_uuid']\n",
    "mask_series = metrics_evaluation_open_world_json_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df[~mask_series]\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac18b354-2d34-444e-aa76-eda3be7b52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicates from the scene stats data frame\n",
    "subset_columns = ['session_uuid', 'scene_id']\n",
    "mask_series = metrics_evaluation_open_world_scene_stats_df.duplicated(subset=subset_columns)\n",
    "if mask_series.any():\n",
    "    metrics_evaluation_open_world_scene_stats_df = metrics_evaluation_open_world_scene_stats_df[~mask_series]\n",
    "    print(metrics_evaluation_open_world_scene_stats_df.shape)\n",
    "    nu.store_objects(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_scene_stats_df=metrics_evaluation_open_world_scene_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a3770-1507-46e6-ac54-ef37067a915d",
   "metadata": {},
   "source": [
    "\n",
    "### Get column and value descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ad4986-b2d3-4902-801e-d1138f7fc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attempt to manufacture some better column names\n",
    "from pandas import read_excel\n",
    "\n",
    "file_path = '../data/xlsx/Metrics_Evaluation_Dataset_organization_for_BBAI.xlsx'\n",
    "dataset_organization_df = read_excel(file_path)\n",
    "\n",
    "mask_series = ~dataset_organization_df.Description.isnull()#re.sub('[^A-Za-z0-9]+', '_', x)\n",
    "df = dataset_organization_df[mask_series]\n",
    "description_dict = df.set_index('Variable').Description.to_dict()\n",
    "new_description_dict = description_dict.copy()\n",
    "for k, v in description_dict.items():\n",
    "    new_description_dict[k] = v\n",
    "    new_description_dict[f'{k}_Text'] = v\n",
    "description_dict = new_description_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe209f6-5ff8-4706-9bd2-0e6b4841b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fix the doubled up descriptions\n",
    "import re\n",
    "\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: ';' in str(x))\n",
    "for row_index, label in dataset_organization_df[mask_series].Labels.items():\n",
    "    labels_list = re.split(' *; *', str(label), 0)\n",
    "    dataset_organization_df.loc[row_index, 'Labels'] = labels_list[0]\n",
    "    \n",
    "    # Get a copy of the row\n",
    "    new_row = dataset_organization_df.loc[row_index].copy()\n",
    "    \n",
    "    # Modify the desired column value\n",
    "    new_row['Labels'] = labels_list[1]\n",
    "    \n",
    "    # Append the new row to the DataFrame\n",
    "    dataset_organization_df = dataset_organization_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec8c760-474f-4fab-b3cd-89061ea13283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a copy of the row\n",
    "mask_series = (dataset_organization_df.Variable == 'AD_Del_Omni')\n",
    "new_row = dataset_organization_df.loc[mask_series].copy()\n",
    "\n",
    "# Modify the desired column value\n",
    "new_row['Variable'] = 'AD_Del_Omni_Text'\n",
    "\n",
    "# Append the new row to the DataFrame\n",
    "dataset_organization_df = dataset_organization_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c63d00b-b33f-424d-b657-028d5f124b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from numpy import nan\n",
    "\n",
    "mask_series = dataset_organization_df.Labels.map(lambda x: '=' in str(x))\n",
    "value_descriptions_columns = dataset_organization_df[mask_series].Variable.unique().tolist()\n",
    "def get_value_description(column_name, column_value):\n",
    "    value_description = ''\n",
    "    if not pd.isna(column_value):\n",
    "        mask_series = (dataset_organization_df.Variable == column_name) & ~dataset_organization_df.Labels.isnull()\n",
    "        if mask_series.any():\n",
    "            df = dataset_organization_df[mask_series]\n",
    "            mask_series = df.Labels.map(lambda label: re.split(' *= *', str(label), 0)[0] == str(int(float(column_value))))\n",
    "            if mask_series.any():\n",
    "                label = df[mask_series].Labels.squeeze()\n",
    "                value_description = re.split(' *= *', str(label), 0)[1]\n",
    "    \n",
    "    return value_description\n",
    "column_name = 'MedRole'\n",
    "column_value = nan\n",
    "get_value_description(column_name, column_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7a30-006e-480d-8531-9585d5526dde",
   "metadata": {},
   "source": [
    "\n",
    "## Provide Correctly Grouped Responder Type Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dac8e96-dc5b-4708-b384-c393a86f867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/first_responder_master_registry_file_stats_df.pkl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EM Resident', 'EMT-Basic', 'Medical Student', 'Other', 'Paramedic']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_frames_dict = nu.load_data_frames(first_responder_master_registry_file_stats_df='')\n",
    "df = data_frames_dict['first_responder_master_registry_file_stats_df']\n",
    "mask_series = ~df.responder_category.isnull()\n",
    "sorted(df[mask_series].responder_category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367b96ab-424f-44bb-897a-39a350f5f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['configData_narrative_narrativeSections00_availableInventory_painMedsCount', 'configData_narrative_narrativeSections01_availableInventory_painMedsCount', 'configData_narrative_narrativeSections02_availableInventory_painMedsCount', 'configData_narrative_narrativeSections03_availableInventory_painMedsCount', 'configData_narrative_narrativeSections04_availableInventory_painMedsCount', 'configData_narrative_narrativeSections05_availableInventory_painMedsCount', 'configData_narrative_narrativeSections06_availableInventory_painMedsCount', 'configData_narrative_narrativeSections07_availableInventory_painMedsCount', 'configData_narrative_narrativeSections08_availableInventory_painMedsCount', 'configData_narrative_narrativeSections09_availableInventory_painMedsCount', 'configData_narrative_narrativeSections10_availableInventory_painMedsCount', 'configData_narrative_narrativeSections11_availableInventory_painMedsCount', 'configData_narrative_narrativeSections12_availableInventory_painMedsCount', 'configData_availableInventory_painMedsCount', 'configData_narrative_narrativeSections13_availableInventory_painMedsCount', 'configData_narrative_narrativeSections14_availableInventory_painMedsCount', 'configData_narrative_narrativeSections15_availableInventory_painMedsCount', 'MedRole', 'MedExp']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[cn for cn in metrics_evaluation_open_world_json_stats_df.columns if 'Med' in cn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7561ce57-9574-4507-a997-cb6504d12f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3561)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "(43, 3562)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responder_category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Medical Student</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM Faculty</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM Resident</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    record_count\n",
       "responder_category              \n",
       "Medical Student               17\n",
       "Other                         16\n",
       "                               4\n",
       "EM Faculty                     2\n",
       "EM Resident                    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add a column that correctly groups responder types\n",
    "new_column_name = 'responder_category'\n",
    "if (new_column_name in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.drop(columns=[new_column_name])\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape)\n",
    "if (new_column_name not in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    metrics_evaluation_open_world_json_stats_df[new_column_name] = metrics_evaluation_open_world_json_stats_df.MedRole.map(\n",
    "        lambda x: ' '.join([r.title() for r in get_value_description('MedRole', x).split(' ')]).replace('Em ', 'EM ')\n",
    "    )\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3564)\n",
    "\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3c4afdd-e65b-4785-97b4-50dfc25bdbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "(43, 3568)\n",
      "overall_category      1\n",
      "global_category       1\n",
      "global_description    1\n",
      "sub_category          1\n",
      "sub_description       1\n",
      "responder_type        1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_category</th>\n",
       "      <th>global_category</th>\n",
       "      <th>global_description</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>sub_description</th>\n",
       "      <th>responder_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EM Resident</th>\n",
       "      <th>DOC</th>\n",
       "      <th>Physicians</th>\n",
       "      <th>DRS</th>\n",
       "      <th>Physician Resident</th>\n",
       "      <th>EM-RES1</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    record_count\n",
       "overall_category global_category global_description sub_category sub_description    responder_type              \n",
       "EM Resident      DOC             Physicians         DRS          Physician Resident EM-RES1                   43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add responder types subgrouping columns\n",
    "groupby_columns = ['overall_category', 'global_category', 'global_description', 'sub_category', 'sub_description', 'responder_type']\n",
    "if any(map(lambda x: x not in metrics_evaluation_open_world_json_stats_df.columns, groupby_columns)):\n",
    "    file_path = '../data/xlsx/Responder_Categories_and_Counts_DPW.xlsx'\n",
    "    dpw_responder_categories_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Get description data frame\n",
    "    mask_series = dpw_responder_categories_df.isna().all(axis='columns')\n",
    "    idx = dpw_responder_categories_df[mask_series].index.min()\n",
    "    where_df = dpw_responder_categories_df.iloc[idx+1:]\n",
    "    \n",
    "    # Get categories data frame\n",
    "    dpw_responder_categories_df = dpw_responder_categories_df.iloc[:idx].dropna(axis='columns', how='all')\n",
    "    dpw_responder_categories_df.columns = ['overall_category', 'responder_type', 'global_category', 'sub_category', 'record_count']\n",
    "    \n",
    "    # Create global description column\n",
    "    columns_list = ['global_category', 'global_description', 'record_count']\n",
    "    df = where_df.iloc[:, 1:4].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    global_description_dict = df.set_index('global_category').global_description.to_dict()\n",
    "    dpw_responder_categories_df['global_description'] = dpw_responder_categories_df.global_category.map(global_description_dict)\n",
    "    \n",
    "    # Create sub description column\n",
    "    columns_list = ['sub_category', 'sub_description', 'record_count']\n",
    "    df = where_df.iloc[:, 5:8].dropna(axis='index', how='all')\n",
    "    df.columns = columns_list\n",
    "    sub_description_dict = df.set_index('sub_category').sub_description.to_dict()\n",
    "    dpw_responder_categories_df['sub_description'] = dpw_responder_categories_df.sub_category.map(sub_description_dict)\n",
    "    \n",
    "    # Add columns to JSON Stats data frame\n",
    "    df = dpw_responder_categories_df[groupby_columns].groupby(groupby_columns).size().reset_index(drop=False)\n",
    "    assert not (df[0] != 1).any(), \"You will have a problem with responder types\"\n",
    "    df = df.drop(columns=[0])\n",
    "    assert not (df.groupby('responder_type').size() != 1).any(), \"You have a problem with responder types\"\n",
    "    if 'responder_type' not in metrics_evaluation_open_world_json_stats_df.columns: metrics_evaluation_open_world_json_stats_df['responder_type'] = 'EM-RES1'\n",
    "    for (overall_category, global_category, global_description, sub_category, sub_description, responder_type), _ in df.groupby(groupby_columns):\n",
    "        mask_series = (metrics_evaluation_open_world_json_stats_df.responder_type == responder_type)\n",
    "        for cn in groupby_columns: metrics_evaluation_open_world_json_stats_df.loc[mask_series, cn] = eval(cn)\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3570)\n",
    "\n",
    "if all(map(lambda x: x in metrics_evaluation_open_world_json_stats_df.columns, groupby_columns)):\n",
    "    print(metrics_evaluation_open_world_json_stats_df[groupby_columns].nunique()) \n",
    "    display(metrics_evaluation_open_world_json_stats_df.groupby(groupby_columns).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "        'record_count', ascending=False\n",
    "    ).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d2d4e-32b8-4b6a-9b6c-27b0d9dde25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to base the CACI data on the sessions in their spreadsheet\n",
    "from pandas import read_excel\n",
    "\n",
    "data_frames_dict = nu.load_data_frames(\n",
    "    metrics_evaluation_open_world_df='', metrics_evaluation_open_world_json_stats_df='', metrics_evaluation_open_world_scene_stats_df=''\n",
    ")\n",
    "logs_df = data_frames_dict['metrics_evaluation_open_world_df']\n",
    "json_stats_df = data_frames_dict['metrics_evaluation_open_world_json_stats_df']\n",
    "scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']\n",
    "print(logs_df.shape)\n",
    "file_path = '../data/xlsx/Metrics_Eval_Participant_data_for_BBAI.xlsx'\n",
    "participant_data_df = read_excel(file_path)\n",
    "uuid_columns = [f'Sim{i}' for i in range(1, 3)]\n",
    "uuid_fn = lambda x: str(x)[:-1] if str(x).endwith('_') else x\n",
    "json_stats_uuids = []\n",
    "for participant_id in range(2_024_201, 2_024_223+1):\n",
    "    mask_series = (participant_data_df.ParticipantID == participant_id)\n",
    "    if mask_series.any():\n",
    "        participant_df = participant_data_df[mask_series]\n",
    "        on_columns = set(json_stats_df.columns).intersection(set(participant_df.columns))\n",
    "        session_uuids_list = participant_df[uuid_columns].applymap(uuid_fn).values.ravel().tolist()\n",
    "        mask_series = json_stats_df.session_uuid.isin(session_uuids_list)\n",
    "        if mask_series.any(): json_stats_uuids.extend(json_stats_df[mask_series].session_uuid.tolist())\n",
    "    else: print(f'You are missing Participant ID #{participant_id} from the Metrics Eval Participant data for BBAI')\n",
    "print(logs_df.shape)\n",
    "# nu.store_objects(metrics_evaluation_open_world_json_stats_df=json_stats_df, verbose=True)\n",
    "# nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=json_stats_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328c08cd-3039-4c7c-bef8-daea10d20550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 22 participants, representing diverse medical roles, completed the ITM scenarios between March 14, 2024 and March 22, 2024. Each participant engaged with two separate open world environments.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "# Filter rows with non-null 'Date' values\n",
    "mask_series = ~json_stats_df.Date.isnull()\n",
    "filtered_df = json_stats_df[mask_series]\n",
    "\n",
    "# Get minimum and maximum dates as datetime objects\n",
    "min_date = filtered_df['Date'].min()\n",
    "max_date = filtered_df['Date'].max()\n",
    "\n",
    "# Format the datetime objects for human-readable output\n",
    "min_date_str = datetime.datetime.strptime(min_date, '%m/%d/%Y').strftime('%B %d, %Y')\n",
    "max_date_str = datetime.datetime.strptime(max_date, '%m/%d/%Y').strftime('%B %d, %Y')\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    f'A total of 22 participants, representing diverse medical roles, completed the ITM scenarios between {min_date_str} and {max_date_str}.'\n",
    "    ' Each participant engaged with two separate open world environments.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce8eb29-d04a-499d-9bce-c04912dc2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BREATHING_CHECKED', 'BUTTON_CLICKED', 'Participant ID', 'SP_O2_TAKEN', 'TRIAGE_LEVEL_WALKED', 'TRIAGE_LEVEL_WALK_IF_CAN', 'TRIAGE_LEVEL_WAVED', 'TRIAGE_LEVEL_WAVE_IF_CAN']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the open world action types\n",
    "import re\n",
    "import os\n",
    "\n",
    "action_type_regex = re.compile(\"^([^,\\r\\n]+),\", re.MULTILINE)\n",
    "file_ending = '.csv'\n",
    "logs_path = '../data/logs/Metrics Evaluation Open World'\n",
    "all_actions_set = set()\n",
    "for sub_directory, directories_list, files_list in os.walk(logs_path):\n",
    "    for file_name in files_list:\n",
    "        if file_name.endswith(file_ending):\n",
    "            file_path = osp.join(sub_directory, file_name)\n",
    "            with open(file_path, 'r', encoding=nu.encoding_type) as f:\n",
    "                text = f.read()\n",
    "                actions_set = set(action_type_regex.findall(text))\n",
    "                all_actions_set.update(actions_set)\n",
    "\n",
    "old_actions_list = [\n",
    "    'BAG_ACCESS', 'BAG_CLOSED', 'INJURY_RECORD', 'INJURY_TREATED', 'PATIENT_DEMOTED', 'PATIENT_ENGAGED', 'PATIENT_RECORD', 'PULSE_TAKEN',\n",
    "    'S_A_L_T_WALKED', 'S_A_L_T_WALK_IF_CAN', 'S_A_L_T_WAVED', 'S_A_L_T_WAVE_IF_CAN', 'TAG_APPLIED', 'TAG_DISCARDED', 'TAG_SELECTED', 'TELEPORT',\n",
    "    'TOOL_APPLIED', 'TOOL_DISCARDED', 'TOOL_HOVER', 'TOOL_SELECTED', 'VOICE_CAPTURE', 'VOICE_COMMAND', 'PLAYER_LOCATION', 'PLAYER_GAZE',\n",
    "    'SESSION_END', 'SESSION_START'\n",
    "]\n",
    "new_actions_list = sorted(all_actions_set.difference(set(old_actions_list)))\n",
    "print(new_actions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67981ab1-67b5-43b7-b51e-8ecad0325690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
