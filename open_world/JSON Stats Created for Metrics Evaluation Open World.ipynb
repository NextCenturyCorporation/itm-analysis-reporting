{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5d88d0-ee28-42bf-b2df-28ef5f83333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f28c498-84bb-4af5-b6ca-9c65ad316395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from FRVRS import fu, nu\n",
    "from pandas import DataFrame, Index, Series, concat, notnull, to_datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c41bbd-d759-42c4-839f-69f6bd450de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_df.pkl.\n",
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/first_responder_master_registry_file_stats_df.pkl.\n",
      "(171766, 124)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data frames\n",
    "data_frames_dict = nu.load_data_frames(metrics_evaluation_open_world_df='', first_responder_master_registry_file_stats_df='')\n",
    "logs_df = data_frames_dict['metrics_evaluation_open_world_df']\n",
    "print(logs_df.shape) # (171766, 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f191acf-470f-4517-8d25-cb634011b94f",
   "metadata": {},
   "source": [
    "\n",
    "# JSON Stats Created for Metrics Evaluation Open World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a897950c-8f66-4d2d-be15-b66d14b72775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "22\n",
      "(43, 3525)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all the Open World JSON Stats into one data frame\n",
    "metrics_evaluation_open_world_json_stats_df = DataFrame([])\n",
    "def get_directory_paths(participant_id, logs_path='../data/logs/Metrics Evaluation Open World'):\n",
    "    \n",
    "    # Get all the directory names which are suffixed by the participant ID\n",
    "    directories_list = os.listdir(logs_path)\n",
    "    \n",
    "    # Loop through the directories and IDs and find a pair that matches\n",
    "    participant_dirs_list = [dir_name for dir_name in directories_list if dir_name.endswith(str(participant_id))]\n",
    "\n",
    "    return participant_dirs_list\n",
    "logs_path = '../data/logs/Human_Sim_Metrics_Data 4-12-2024'\n",
    "for participant_id in range(2_024_201, 2_024_223+1):\n",
    "    for dir_name in get_directory_paths(participant_id, logs_path):\n",
    "        \n",
    "        # Add the JSONs to the data frame\n",
    "        folder_path = osp.join(logs_path, dir_name)\n",
    "        \n",
    "        # Iterate over the files in the current subdirectory\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            \n",
    "            # If the file is a JSON file\n",
    "            if file_name.endswith('.json'):\n",
    "\n",
    "                # Create a data frame from the flattened dictionary\n",
    "                json_path = osp.join(folder_path, file_name)\n",
    "                with open(json_path, 'r') as f: file_json = json.load(f)\n",
    "                row_dict = {\n",
    "                    'participant_id': participant_id,\n",
    "                    'sub_directory': folder_path.split('/')[-1],\n",
    "                    'json_file_name': file_name\n",
    "                }\n",
    "                flattened_json_dict = nu.get_row_dictionary(file_json, row_dict=row_dict, key_prefix='')\n",
    "                \n",
    "                # You've got to clean the Session IDs\n",
    "                session_uuid = flattened_json_dict.pop('sessionId')\n",
    "                if session_uuid.endswith('_'): session_uuid = session_uuid[:-1]\n",
    "                flattened_json_dict['session_uuid'] = session_uuid\n",
    "                json_stats_df = DataFrame(flattened_json_dict, index=Index([0]))\n",
    "                \n",
    "                # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "                metrics_evaluation_open_world_json_stats_df = pd.concat([metrics_evaluation_open_world_json_stats_df, json_stats_df], axis='index')\n",
    "\n",
    "metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.reset_index(drop=True)\n",
    "nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "print(metrics_evaluation_open_world_json_stats_df.participant_id.nunique()) # 22\n",
    "print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a77265-2d8c-400f-be3d-3030a7841b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'session_uuid', 'file_name', 'patient_demoted_health_time_remaining', 'csv_file_name', 'patient_engaged_health_level', 'player_location_left_hand_location', 'bag_access_location', 'injury_record_injury_treated', 'patient_record_health_level', 'voice_capture_command_description', 'player_location_right_hand_location', 'patient_demoted_health_level', 'injury_record_injury_treated_with_wrong_treatment', 'participant_id'}\n",
      "(43, 14)\n",
      "['participant_id', 'session_uuid']\n",
      "(43, 3537)\n",
      "(43, 14)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "(43, 3537)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics_evaluation_open_world_json_stats_df = nu.load_object('metrics_evaluation_open_world_json_stats_df')\n",
    "if 'logger_version' not in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "    \n",
    "    # Get the columns that consistently have only one value in them per session\n",
    "    single_value_cols_set = set(logs_df.columns)\n",
    "    for session_uuid, session_df in logs_df.groupby('session_uuid'):\n",
    "        single_value_cols = set([col for col in session_df.columns if session_df[col].nunique() == 1])\n",
    "        single_value_cols_set = single_value_cols_set.intersection(single_value_cols)\n",
    "    print(single_value_cols_set)\n",
    "    rows_list = []\n",
    "    for session_uuid, session_df in logs_df[single_value_cols_set].dropna(axis='columns', how='all').groupby('session_uuid'):\n",
    "        row_dict = {cn: session_df[cn].dropna().max() for cn in session_df.columns}\n",
    "        rows_list.append(row_dict)\n",
    "    single_value_cols_df = DataFrame(rows_list)\n",
    "    print(single_value_cols_df.shape)\n",
    "    \n",
    "    on_columns = sorted(set(metrics_evaluation_open_world_json_stats_df.columns).intersection(set(single_value_cols_df.columns)))\n",
    "    print(on_columns)\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.merge(\n",
    "        single_value_cols_df, how='left', on=on_columns\n",
    "    )\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape)\n",
    "    print(single_value_cols_df.shape)\n",
    "    \n",
    "    # Save so you don't have to run it again\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    \n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1700fe83-21ea-44a3-9001-4aba4abb6808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 27)\n",
      "['participant_id']\n",
      "(43, 3537)\n",
      "(22, 27)\n",
      "(43, 3563)\n",
      "Of the 43 JSON files, only 14 of them match with either Sim1 or Sim2.\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics_evaluation_open_world_json_stats_df = nu.load_object('metrics_evaluation_open_world_json_stats_df')\n",
    "if 'MedExp' not in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "    from pandas import read_excel\n",
    "    file_path = '../data/xlsx/Metrics_Eval_Participant_data_for_BBAI.xlsx'\n",
    "    participant_data_df = read_excel(file_path).rename(columns={'ParticipantID': 'participant_id', 'Date': 'participation_date'})\n",
    "    for i in range(2):\n",
    "        cn = 'Sim' + str(i+1)\n",
    "        participant_data_df[cn] = participant_data_df[cn].map(lambda x: str(x)[:-1] if str(x).endswith('_') else x)\n",
    "    print(participant_data_df.shape)\n",
    "    sim1_list = participant_data_df.Sim1.tolist()\n",
    "    assert len(sim1_list) == len(set(sim1_list)), \"Sim1 has duplicates\"\n",
    "    sim2_list = participant_data_df.Sim2.tolist()\n",
    "    assert len(sim2_list) == len(set(sim2_list)), \"Sim2 has duplicates\"\n",
    "    assert set(sim1_list).intersection(set(sim2_list)) == set(), \"There are duplicates between Sim1 and Sim2\"\n",
    "    \n",
    "    # See if you can merge on participant_id\n",
    "    on_columns = sorted(set(metrics_evaluation_open_world_json_stats_df.columns).intersection(set(participant_data_df.columns)))\n",
    "    print(on_columns)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape)\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.merge(\n",
    "        participant_data_df, how='left', on=on_columns\n",
    "    )\n",
    "    print(participant_data_df.shape)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape)\n",
    "    mask_series = (metrics_evaluation_open_world_json_stats_df.session_uuid == metrics_evaluation_open_world_json_stats_df.Sim1)\n",
    "    mask_series |= (metrics_evaluation_open_world_json_stats_df.session_uuid == metrics_evaluation_open_world_json_stats_df.Sim2)\n",
    "    print(\n",
    "        f'Of the {metrics_evaluation_open_world_json_stats_df.shape[0]} JSON files, only'\n",
    "        f' {metrics_evaluation_open_world_json_stats_df[mask_series].shape[0]} of them match with either Sim1 or Sim2.'\n",
    "    )\n",
    "    \n",
    "    # Check if the various partipant id columns are inconsistent\n",
    "    columns_list = [cn for cn in metrics_evaluation_open_world_json_stats_df.columns if cn.lower().startswith('participant') and cn.lower().endswith('id')]\n",
    "    df = metrics_evaluation_open_world_json_stats_df[columns_list]\n",
    "    for cn in columns_list:\n",
    "        df[cn] = df[cn].map(lambda x: str(x).strip())\n",
    "    mask_series = (df[columns_list[0]] != df[columns_list[1]])\n",
    "    assert not mask_series.any(), \"The various partipant id columns are inconsistent\"\n",
    "    \n",
    "    # Save so you don't have to run it again\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f21cd1f-f21a-47e6-bdde-71c7e85d003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove any duplicate session IDs\n",
    "mask_series = metrics_evaluation_open_world_json_stats_df.duplicated(subset='session_uuid')\n",
    "if mask_series.any():\n",
    "    display(metrics_evaluation_open_world_json_stats_df[mask_series].dropna(axis='columns', how='all')); raise\n",
    "    metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df[~mask_series]\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (60, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1e0e76-7e4b-4937-af10-7ba60cde9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have 43 sessioms in my JSON Stats data frame without file dates.\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fix the null file dates\n",
    "if 'session_file_date' not in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "    metrics_evaluation_open_world_json_stats_df['session_file_date'] = pd.NaT\n",
    "mask_series = metrics_evaluation_open_world_json_stats_df.session_file_date.isnull()\n",
    "if mask_series.any():\n",
    "    print(f'I have {mask_series.sum()} sessioms in my JSON Stats data frame without file dates.')\n",
    "    for session_uuid, idx_df in metrics_evaluation_open_world_json_stats_df[mask_series].groupby('session_uuid'):\n",
    "        \n",
    "        # Get the whole session history\n",
    "        mask_series = (logs_df.session_uuid == session_uuid)\n",
    "        assert mask_series.any(), f\"You're missing a Session ID {session_uuid} in logs_df\"\n",
    "        session_df = logs_df[mask_series]\n",
    "\n",
    "        mask_series = ~session_df.event_time.isnull()\n",
    "        assert mask_series.any(), f\"Session ID {session_uuid} doesn't have an event times in logs_df\"\n",
    "        session_file_date = session_df[mask_series].event_time.min().date()\n",
    "        metrics_evaluation_open_world_json_stats_df.loc[idx_df.index, 'session_file_date'] = session_file_date\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    mask_series = metrics_evaluation_open_world_json_stats_df.session_file_date.isnull()\n",
    "    if mask_series.any():\n",
    "        print(f'I still have {mask_series.sum()} sessioms in my JSON Stats data frame without file dates.')\n",
    "        display(metrics_evaluation_open_world_json_stats_df[mask_series].dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3d847b-f084-4e86-b377-ece008013507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3566)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add file start time\n",
    "if ('file_start_time' not in metrics_evaluation_open_world_json_stats_df.columns) or ('file_stop_time' not in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    sub_directory = '../data/logs'\n",
    "    import os.path as osp\n",
    "    if 'file_name' in metrics_evaluation_open_world_json_stats_df.columns:\n",
    "        for file_name, idx_df in metrics_evaluation_open_world_json_stats_df.groupby('file_name'):\n",
    "            \n",
    "            # Construct the full path to the file\n",
    "            file_path = osp.join(sub_directory, file_name)\n",
    "            \n",
    "            # Attempt to read CSV file using pandas\n",
    "            try:\n",
    "                import pandas as pd\n",
    "                file_df = pd.read_csv(file_path, header=None, index_col=False)\n",
    "            \n",
    "            # If unsuccessful, try using a reader\n",
    "            except:\n",
    "                rows_list = []\n",
    "                with open(file_path, 'r') as f:\n",
    "                    import csv\n",
    "                    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "                    for values_list in reader:\n",
    "                        if (values_list[-1] == ''): values_list.pop(-1)\n",
    "                        rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "                from pandas import DataFrame\n",
    "                file_df = DataFrame(rows_list)\n",
    "            \n",
    "            ts_series = to_datetime(file_df[2], infer_datetime_format=True)\n",
    "            metrics_evaluation_open_world_json_stats_df.loc[idx_df.index, 'file_start_time'] = ts_series.min().to_pydatetime()\n",
    "            metrics_evaluation_open_world_json_stats_df.loc[idx_df.index, 'file_stop_time'] = ts_series.max().to_pydatetime()\n",
    "        print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3538)\n",
    "        nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "        nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b506d5-b30c-4c91-8783-089353e3c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_scene_stats_df.pkl.\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "(43, 3567)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_a_one_triage_file</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      record_count\n",
       "is_a_one_triage_file              \n",
       "False                            2\n",
       "True                            41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get a sample with a clear count of responders\n",
    "new_column_name = 'is_a_one_triage_file'\n",
    "# if (new_column_name in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    # metrics_evaluation_open_world_json_stats_df = metrics_evaluation_open_world_json_stats_df.drop(columns=new_column_name)\n",
    "if (new_column_name not in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    metrics_evaluation_open_world_json_stats_df[new_column_name] = False\n",
    "    data_frames_dict = nu.load_data_frames(metrics_evaluation_open_world_scene_stats_df='')\n",
    "    scene_stats_df = data_frames_dict['metrics_evaluation_open_world_scene_stats_df']\n",
    "    \n",
    "    # Assume a 1:1 correspondence between file name and UUID from the logs data frame build\n",
    "    for session_uuid, session_df in metrics_evaluation_open_world_json_stats_df.groupby('session_uuid'):\n",
    "        assert session_df.shape[0] == 1, \"You've got duplicate session UUIDs\"\n",
    "        \n",
    "        # Filter in the triage files in this UUID\n",
    "        mask_series = (scene_stats_df.session_uuid == session_uuid) & (scene_stats_df.scene_type == 'Triage')\n",
    "        \n",
    "        # Get whether the file has only one triage run\n",
    "        triage_scene_count = len(scene_stats_df[mask_series].groupby('scene_id').groups)\n",
    "        is_a_one_triage_file = bool(triage_scene_count == 1)\n",
    "        \n",
    "        metrics_evaluation_open_world_json_stats_df.loc[session_df.index, new_column_name] = is_a_one_triage_file\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3539)\n",
    "\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eda8907-bbae-493d-888a-2c84e8d0f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n",
      "(43, 3568)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_in_registry</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                record_count\n",
       "is_in_registry              \n",
       "False                     43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "new_column_name = 'is_in_registry'\n",
    "if (new_column_name not in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    metrics_evaluation_open_world_json_stats_df[new_column_name] = False\n",
    "    \n",
    "    # Store the results and show the new data frame shape\n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df)\n",
    "    print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3540)\n",
    "\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c962f3e-2332-4398-8815-331f2c3ea1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3569)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_layout</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Desert</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submarine</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  record_count\n",
       "encounter_layout              \n",
       "Desert                      11\n",
       "Jungle                      11\n",
       "Submarine                   11\n",
       "Urban                       10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Fix the encounter_layout column based on the set of patients in the scene\n",
    "new_column_name = 'encounter_layout'\n",
    "desert_patients_list = ['Open World Marine 1 Female Root', 'Open World Marine 2 Male Root', 'Open World Civilian 1 Male Root', 'Open World Civilian 2 Female Root']\n",
    "jungle_patients_list = ['Open World Marine 1 Male Root', 'Open World Marine 2 Female Root', 'Open World Marine 3 Male Root', 'Open World Marine 4 Male Root']\n",
    "submarine_patients_list = ['Navy Soldier 1 Male Root', 'Navy Soldier 2 Male Root', 'Navy Soldier 3 Male Root', 'Navy Soldier 4 Female Root']\n",
    "urban_patients_list = ['Marine 1 Male Root', 'Marine 2 Male Root', 'Marine 3 Male Root', 'Marine 4 Male Root', 'Civilian 1 Female Root']\n",
    "for (session_uuid, scene_id), scene_df in logs_df.groupby(fu.scene_groupby_columns):\n",
    "    for env_str in ['desert', 'jungle', 'submarine', 'urban']:\n",
    "        patients_list = eval(f'{env_str}_patients_list')\n",
    "        if all(map(lambda patient_id: patient_id in scene_df.patient_id.unique().tolist(), patients_list)):\n",
    "            mask_series = (metrics_evaluation_open_world_json_stats_df.session_uuid == session_uuid)\n",
    "            metrics_evaluation_open_world_json_stats_df.loc[mask_series, new_column_name] = env_str.title()\n",
    "            nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=False)\n",
    "            nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=False)\n",
    "    \n",
    "print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3541)\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby(new_column_name, dropna=False).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cec1d-6fc6-449a-b86e-9fbf73613c67",
   "metadata": {},
   "source": [
    "\n",
    "Please use the data attached for exploratory analyses in our open world scenarios. The document attached defines each of the variables (by column) and each row represents one human.\n",
    "\n",
    "You should have TWO simulation data files for each participant (row) and they should be matched up by the UUIDs in columns 3 and 4 (they should be two different environments in case you have those in separate folders).\n",
    "\n",
    "I would like you to look for any patterns in these data, especially related to the variables “ST_KDMA_Text” “ST_KDMA_Sim” “AD_KDMA_Text” “AD_KDMA_Sim”\n",
    "Let me know if you have any questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6796ca-e7aa-4951-903f-5436e86706d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_sim1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         record_count\n",
       "in_sim1              \n",
       "False              21\n",
       "True               22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_sim2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         record_count\n",
       "in_sim2              \n",
       "False              22\n",
       "True               21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Add file start time\n",
    "if ('in_sim1' not in metrics_evaluation_open_world_json_stats_df.columns) or ('in_sim2' not in metrics_evaluation_open_world_json_stats_df.columns):\n",
    "    metrics_evaluation_open_world_json_stats_df['in_sim1'] = False\n",
    "    metrics_evaluation_open_world_json_stats_df['in_sim2'] = False\n",
    "    \n",
    "    from pandas import read_excel\n",
    "    file_path = '../data/xlsx/Metrics_Eval_Participant_data_for_BBAI.xlsx'\n",
    "    participant_data_df = read_excel(file_path)\n",
    "    \n",
    "    mask_series = ~participant_data_df.Sim1.isnull() & (participant_data_df.Sim1 != '')\n",
    "    sim1_session_uuids_list = [u[:-1] if u.endswith('_') else u for u in sorted(participant_data_df[mask_series].Sim1)]\n",
    "    mask_series = ~participant_data_df.Sim2.isnull() & (participant_data_df.Sim2 != '')\n",
    "    sim2_session_uuids_list = [u[:-1] if u.endswith('_') else u for u in sorted(participant_data_df[mask_series].Sim2)]\n",
    "    assert set(sim1_session_uuids_list).intersection(set(sim2_session_uuids_list)) == set(), \"The participant ID groupings are not distinct\"\n",
    "    \n",
    "    mask_series = metrics_evaluation_open_world_json_stats_df.session_uuid.isin(sim1_session_uuids_list)\n",
    "    metrics_evaluation_open_world_json_stats_df.loc[mask_series, 'in_sim1'] = True\n",
    "    mask_series = metrics_evaluation_open_world_json_stats_df.session_uuid.isin(sim2_session_uuids_list)\n",
    "    metrics_evaluation_open_world_json_stats_df.loc[mask_series, 'in_sim2'] = True\n",
    "    \n",
    "    nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=True)\n",
    "    nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=True)\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby('in_sim1', dropna=False).size().to_frame().rename(columns={0: 'record_count'}))\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby('in_sim2', dropna=False).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a661464-fce6-4501-86e9-47dea41ae908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3571)\n",
      "Pickling to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/pkl/metrics_evaluation_open_world_json_stats_df.pkl\n",
      "Saving to /mnt/c/Users/DaveBabbitt/Documents/GitHub/itm-analysis-reporting/saves/csv/metrics_evaluation_open_world_json_stats_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the participant ID columns to numeric\n",
    "from pandas import to_numeric\n",
    "\n",
    "columns_list = [cn for cn in metrics_evaluation_open_world_json_stats_df.columns if 'partici' in cn.lower()]\n",
    "for cn in columns_list: metrics_evaluation_open_world_json_stats_df[cn] = to_numeric(metrics_evaluation_open_world_json_stats_df[cn], errors='coerce')\n",
    "print(metrics_evaluation_open_world_json_stats_df.shape) # (43, 3570)\n",
    "nu.store_objects(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=True)\n",
    "nu.save_data_frames(metrics_evaluation_open_world_json_stats_df=metrics_evaluation_open_world_json_stats_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b2eeca-75f1-42d0-aa34-c89e78092c20",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4088/2296409741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "\n",
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4583342-927d-4163-81ff-5cfb5a90d1f6",
   "metadata": {},
   "source": [
    "\n",
    "# Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74390b11-d956-43a4-84b5-f6121c2c3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# See if you can merge on Sim1's session_uuid\n",
    "sim1_df = metrics_evaluation_open_world_json_stats_df.merge(participant_data_df, left_on='session_uuid', right_on='Sim1', how='inner')\n",
    "print(sim1_df.shape)\n",
    "mask_series = (sim1_df.participant_id_x != sim1_df.participant_id_y)\n",
    "assert mask_series.sum() == 0, f\"{mask_series.sum()} files have mismatched Participant IDs in Sim1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f7d94-1edf-4a98-986e-d416ca82915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# See if you can merge on Sim2's session_uuid\n",
    "sim2_df = metrics_evaluation_open_world_json_stats_df.merge(participant_data_df, left_on='session_uuid', right_on='Sim2', how='inner')\n",
    "print(sim2_df.shape)\n",
    "mask_series = (sim2_df.participant_id_x != sim2_df.participant_id_y)\n",
    "assert mask_series.sum() == 0, f\"{mask_series.sum()} files have mismatched Participant IDs in Sim2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596d37b-2012-4201-b63f-bed6f4a2cbbd",
   "metadata": {},
   "source": [
    "\n",
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bf96c-358a-46a9-9b66-9cb4a4198d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(metrics_evaluation_open_world_json_stats_df.participant_id.nunique()) # 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d67a2b-64d2-4142-86c4-46df9cd464e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show numeric columns\n",
    "column_descriptions_df = nu.get_column_descriptions(participant_data_df)\n",
    "mask_series = column_descriptions_df.dtype.isin(['float64', 'int64'])\n",
    "columns_set = set(column_descriptions_df[mask_series].column_name).difference(set(['ParticipantID']))\n",
    "list(columns_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfba631-7a72-4022-8332-32b43466ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Walk through the logs, getting only file names and session_uuids\n",
    "from pandas import DataFrame, read_csv, concat\n",
    "import os\n",
    "from os import path as osp\n",
    "\n",
    "important_columns_list = ['file_name', 'session_uuid']\n",
    "file_names_and_session_uuids_df = DataFrame([], columns=important_columns_list)\n",
    "\n",
    "# Iterate over the subdirectories, directories, and files in the logs folder\n",
    "logs_folder = '../data/logs'\n",
    "for sub_directory, directories_list, files_list in os.walk(logs_folder):\n",
    "    \n",
    "    # Create a data frame to store the data for the current subdirectory\n",
    "    sub_directory_df = DataFrame([], columns=important_columns_list)\n",
    "    \n",
    "    # Iterate over the files in the current subdirectory\n",
    "    for file_name in files_list:\n",
    "        \n",
    "        # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "        if file_name.endswith('.csv'):\n",
    "            # sub_directory_df = fu.process_files(sub_directory_df, sub_directory, file_name, verbose=verbose)\n",
    "            \n",
    "            # Construct the full path to the file\n",
    "            file_path = osp.join(sub_directory, file_name)\n",
    "            \n",
    "            # Attempt to read CSV file using pandas\n",
    "            try: file_df = read_csv(file_path, header=None, index_col=False)\n",
    "            \n",
    "            # If unsuccessful, try using a reader\n",
    "            except:\n",
    "                rows_list = []\n",
    "                with open(file_path, 'r') as f:\n",
    "                    import csv\n",
    "                    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "                    for values_list in reader:\n",
    "                        if (values_list[-1] == ''): values_list.pop(-1)\n",
    "                        rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "                file_df = DataFrame(rows_list)\n",
    "            \n",
    "            # Ignore small files and return the subdirectory data frame unharmed\n",
    "            if (file_df.shape[1] >= 16):\n",
    "                \n",
    "                # Add file name  to the data frame\n",
    "                file_dir_suffix = osp.abspath(sub_directory).replace(osp.abspath(logs_folder) + os.sep, '')\n",
    "                file_df['file_name'] = '/'.join(file_dir_suffix.split(os.sep)) + '/' + file_name\n",
    "                \n",
    "                # Name the global columns\n",
    "                columns_list = ['action_type', 'action_tick', 'event_time', 'session_uuid']\n",
    "                file_df.columns = columns_list + file_df.columns.tolist()[len(columns_list):]\n",
    "\n",
    "                # Remove all but the file name and session columns\n",
    "                file_df = file_df[important_columns_list].drop_duplicates()\n",
    "                \n",
    "                # Append the data frame for the current file to the data frame for the current subdirectory\n",
    "                sub_directory_df = concat([sub_directory_df, file_df], axis='index')\n",
    "    \n",
    "    # Append the data frame for the current subdirectory to the main data frame\n",
    "    file_names_and_session_uuids_df = concat([file_names_and_session_uuids_df, sub_directory_df], axis='index')\n",
    "    \n",
    "file_names_and_session_uuids_df = file_names_and_session_uuids_df.reset_index(drop=True)\n",
    "mask_series = file_names_and_session_uuids_df.session_uuid.isin(sim_session_uuids_list)\n",
    "df = file_names_and_session_uuids_df[mask_series]\n",
    "print(df.shape) # (43, 3)\n",
    "display(df.sample(5).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb13752-c472-4602-93ee-d6dcc9fe96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "search_regex = re.compile('Urban', re.IGNORECASE)\n",
    "columns_list = nu.get_regexed_columns(metrics_evaluation_open_world_json_stats_df, search_regex=search_regex)\n",
    "df = nu.get_regexed_dataframe(metrics_evaluation_open_world_json_stats_df, columns_list, search_regex=search_regex)\n",
    "df.sample(4)[columns_list].dropna(axis='columns', how='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9311d6-217a-413e-87f6-1d3ea612e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = [\n",
    "    'encounter_layout', 'configData_narrative_narrativeDescription', 'configData_scene', 'configData_scenarioData_name', 'configData_scenarioData_description'\n",
    "]\n",
    "for cn in columns_list: display(metrics_evaluation_open_world_json_stats_df.groupby(cn, dropna=False).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05571e9-32e6-4564-9325-5352ffd22129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_subgraph(sub_graph, suptitle='Within-function Function Calls', nodes_list_list=None, node_color='b', verbose=False):\n",
    "    \n",
    "    # Vertically separate the labels for easier readability\n",
    "    layout_items = nx.spring_layout(sub_graph).items()\n",
    "    left_lim, right_lim = -1500, 1500\n",
    "    bottom_lim, top_lim = left_lim * nu.twitter_aspect_ratio, right_lim * nu.twitter_aspect_ratio\n",
    "    rows_list = [{'node_name': node_name, 'layout_x': pos_array[0], 'layout_y': pos_array[1]} for node_name, pos_array in layout_items]\n",
    "    df = DataFrame(rows_list).sort_values('layout_x')\n",
    "    df['x_tick'] = [int(round(el)) for el in pd.cut(np.array([left_lim, right_lim]), len(sub_graph.nodes)+1, retbins=True)[1]][1:-1]\n",
    "    df = df.sort_values('layout_y')\n",
    "    df['y_tick'] = [int(round(el)) for el in pd.cut(np.array([bottom_lim, top_lim]), len(sub_graph.nodes)+1, retbins=True)[1]][1:-1]\n",
    "    \n",
    "    # Create the layout dictionary\n",
    "    layout_dict = {}\n",
    "    for row_index, row_series in df.iterrows():\n",
    "        node_name = row_series.node_name\n",
    "        layout_x = row_series.x_tick\n",
    "        layout_y = row_series.y_tick\n",
    "        layout_dict[node_name] = np.array([float(layout_x), float(layout_y)])\n",
    "    \n",
    "    # Draw the graph using the layout\n",
    "    fig = plt.figure(figsize=(18, 7), facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.axis('off')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    fig.suptitle(suptitle, fontsize=24)\n",
    "    \n",
    "    # Make the nodes the node_color\n",
    "    if nodes_list_list is None:\n",
    "        node_collection = nx.draw_networkx_nodes(\n",
    "            G=sub_graph, pos=layout_dict, alpha=0.33, node_color=node_color.reshape(1, -1), node_size=150\n",
    "        )\n",
    "        edge_collection = nx.draw_networkx_edges(\n",
    "            G=sub_graph, pos=layout_dict, alpha=0.25, width=[edge_tuple[2]['weight'] for edge_tuple in sub_graph.edges(data=True)]\n",
    "        )\n",
    "        labels_collection = nx.draw_networkx_labels(G=sub_graph, pos=layout_dict, font_size=10)\n",
    "    \n",
    "    # Color each nodes list differently\n",
    "    else:\n",
    "        if verbose: display(nodes_list_list)\n",
    "        color_cycler = nu.get_color_cycler(len(nodes_list_list))\n",
    "        for nodes_list, fcd in zip(nodes_list_list, color_cycler()):\n",
    "            if verbose: display(fcd['color'])\n",
    "            node_color = fcd['color'].reshape(1, -1)\n",
    "            sub_subgraph = nx.subgraph(sub_graph, nodes_list)\n",
    "            node_collection = nx.draw_networkx_nodes(G=sub_subgraph, pos=layout_dict, alpha=0.33, node_color=node_color, node_size=150)\n",
    "            edge_collection = nx.draw_networkx_edges(G=sub_subgraph, pos=layout_dict, alpha=0.25)\n",
    "            labels_collection = nx.draw_networkx_labels(G=sub_subgraph, pos=layout_dict, font_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4465cc-2739-4b37-b337-802446438a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import networkx as nx\n",
    "\n",
    "# Create data structures to tally the nodes, edges, and weights\n",
    "edge_tuple_dict = {}\n",
    "for pair in itertools.combinations(columns_list, 2):\n",
    "    df = metrics_evaluation_open_world_json_stats_df[list(pair)].drop_duplicates().sort_values(list(pair))\n",
    "    # print()\n",
    "    # print(*pair)\n",
    "    eval_list = []\n",
    "    for record_dict in df.dropna(axis='index', how='any').to_dict(orient='records'):\n",
    "        values_list = list(record_dict.values())\n",
    "        name_similarities_df = nu.check_for_typos(*[[v] for v in values_list])\n",
    "        # print(*values_list)\n",
    "        eval_list.append(1.0 if (values_list[0] in values_list[1]) else name_similarities_df.max_similarity.squeeze())\n",
    "    similarity_measure = np.min(eval_list)\n",
    "    edge_tuple_dict[pair] = similarity_measure#if similarity_measure > 0.08: \n",
    "\n",
    "# Create the directed graph\n",
    "dg = nx.DiGraph()\n",
    "dg.add_nodes_from(columns_list)\n",
    "dg.add_weighted_edges_from([(k[0], k[1], 10*v) for k, v in edge_tuple_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224a8eb-4bb4-4709-9810-58217973e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "show_subgraph(dg, suptitle='Encouter Layout Features', nodes_list_list=None, node_color=np.array([0.4, 0.4, 0.4, 1.0]), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b5840-b7f8-4db7-b528-08a849d960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['configData_scene', 'configData_scenarioData_name', 'configData_scenarioData_description']\n",
    "display(metrics_evaluation_open_world_json_stats_df[columns_list].drop_duplicates().sort_values(columns_list))\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby(columns_list, dropna=False).size().to_frame().rename(columns={0: 'record_count'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e18d9-46db-426e-a8f7-f67bf2fb4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_evaluation_open_world_json_stats_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aafe2-11ac-41ea-971e-a867698c8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the unique count of each column\n",
    "for cn in sorted(metrics_evaluation_open_world_json_stats_df.columns): print(cn, metrics_evaluation_open_world_json_stats_df[cn].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b7241-6d68-4839-a3f4-e7a02c755501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted(metrics_evaluation_open_world_json_stats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ed8b5-ea66-4fbf-8f3e-a8d9c3c06632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(metrics_evaluation_open_world_json_stats_df.groupby('responder_type').size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e871a-71d8-4468-8135-c01481485a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show all patient names\n",
    "old_patient_names_set = set([\n",
    "    'Adept Shooter Root', 'Adept Victim Root', 'Broken Bob Root', 'Broken Gloria Root', 'Broken Helga Root', 'Civilian 1 Female Root', 'Civilian 1 Root',\n",
    "    'Civilian 2 Root', 'Intelligence Officer Root', 'Local Civilian with Internal Bleeding Root', 'Local Soldier 1 Root', 'Marine 1 Male Root', 'Marine 2 Male Root',\n",
    "    'Marine 3 Male Root', 'Marine 4 Male Root', 'Marine with Leg Amputation Root', 'Marine with Narrative Root', 'NPC 1 Root', 'NPC 2 Root', 'NPC 3 Root',\n",
    "    'NPC 4 Root', 'NPC Root', 'Navy Soldier 1 Male Root', 'Navy Soldier 2 Male Root', 'Navy Soldier 3 Male Root', 'Navy Soldier 4 Female Root',\n",
    "    'Navy Solider 4 Female Root', 'Open World Civilian 1 Male Root', 'Open World Civilian 2 Female Root', 'Open World Marine 1 Female Root',\n",
    "    'Open World Marine 1 Male Root', 'Open World Marine 2 Female Root', 'Open World Marine 2 Male Root', 'Open World Marine 3 Male Root',\n",
    "    'Open World Marine 4 Male Root', 'Patient U Root', 'Patient V Root', 'Patient W Root', 'Patient X Root', 'Simulation Root', 'Tutorial Military Marine Root',\n",
    "    'US Soldier 1 Root', 'bystander Root', 'electrician Root', 'patient U Root', 'patient V Root', 'patient W Root', 'patient X Root'\n",
    "])\n",
    "mask_series = ~logs_df.patient_id.isnull()\n",
    "all_patient_names = sorted(logs_df[mask_series].patient_id.unique())\n",
    "old_patient_names_set.symmetric_difference(set(all_patient_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac8e96-dc5b-4708-b384-c393a86f867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show all the responder types in the registry\n",
    "df = data_frames_dict['first_responder_master_registry_file_stats_df']\n",
    "mask_series = ~df.responder_type.isnull()\n",
    "sorted(df[mask_series].responder_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ea3f9-fc85-430d-b6c5-b399e1bb40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show if you have any \"file\" columns in the logs data frame\n",
    "sorted([cn for cn in logs_df.columns if 'file' in cn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f517fe-1527-4a3a-86be-ad764256af14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
