{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0639f1-09e0-43e0-9609-a4fab9f7a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3626480e-7e39-44bd-9e6a-2a8d26565ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up notebook\n",
    "%pprint\n",
    "import sys\n",
    "if ('../py' not in sys.path): sys.path.insert(1, '../py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f09e164-f476-48f1-8744-d1e98397f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load libraries\n",
    "from FRVRS import nu, fu\n",
    "from numpy import nan, isnan\n",
    "from os import listdir as listdir, makedirs as makedirs, path as osp, remove as remove, sep as sep, walk as walk\n",
    "from pandas import (\n",
    "    CategoricalDtype, DataFrame, Index, NaT, Series, concat, get_dummies, isna, notnull, read_csv, read_excel, to_datetime, to_numeric\n",
    ")\n",
    "from re import split, search, sub, MULTILINE\n",
    "from scipy.stats import f_oneway, ttest_ind, kruskal, norm\n",
    "import itertools\n",
    "import re\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ea4709-6d84-4614-8262-b0f0bbcb65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find unaccounted-for patient IDs in weird columns\n",
    "desert_patients_list = [\n",
    "    'Open World Marine 1 Female Root', 'Open World Marine 2 Male Root', 'Open World Civilian 1 Male Root', 'Open World Civilian 2 Female Root'\n",
    "]\n",
    "jungle_patients_list = [\n",
    "    'Open World Marine 1 Male Root', 'Open World Marine 2 Female Root', 'Open World Marine 3 Male Root', 'Open World Marine 4 Male Root'\n",
    "]\n",
    "submarine_patients_list = ['Navy Soldier 1 Male Root', 'Navy Soldier 2 Male Root', 'Navy Soldier 3 Male Root', 'Navy Soldier 4 Female Root']\n",
    "urban_patients_list = ['Marine 1 Male Root', 'Marine 2 Male Root', 'Marine 3 Male Root', 'Marine 4 Male Root', 'Civilian 1 Female Root']\n",
    "patients_set = set(desert_patients_list + jungle_patients_list + submarine_patients_list + urban_patients_list)\n",
    "patients_regex = re.compile(r',(' + '|'.join(patients_set) + r')\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5d739-081e-4963-bbe1-9fd9a818b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add all mentions of TA3 patients to its own CSV file\n",
    "import csv\n",
    "\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)\n",
    "output_file_path = osp.join(fu.saves_folder, 'csv', 'desert_jungle_submarine_urban_patients.csv')\n",
    "with open(output_file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "with open(output_file_path, mode='a', encoding=nu.encoding_type) as f_output:\n",
    "    for dir_name in directories_list:\n",
    "        folder_path = osp.join(logs_path, dir_name)\n",
    "        for sub_directory, directories_list, files_list in walk(folder_path):\n",
    "            \n",
    "            # Iterate over the files in the current subdirectory\n",
    "            for file_name in files_list:\n",
    "                \n",
    "                # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "                if file_name.endswith('.csv'):\n",
    "                    \n",
    "                    # Construct the full path to the file\n",
    "                    file_path = osp.join(sub_directory, file_name)\n",
    "                    \n",
    "                    # Read CSV file\n",
    "                    with open(file_path, 'r') as f_input:\n",
    "                        for line_str in f_input:\n",
    "                            if patients_regex.search(line_str):\n",
    "                                print(line_str, end='', file=f_output)\n",
    "\n",
    "# Read CSV file using a CSV reader\n",
    "rows_list = []\n",
    "with open(osp.abspath(output_file_path), 'r', encoding=nu.encoding_type) as f:\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for values_list in reader:\n",
    "        rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "file_df = DataFrame(rows_list).dropna(axis='columns', how='all').dropna(axis='index', how='all')\n",
    "\n",
    "# Show the columns that have the patient's names in them\n",
    "patients_regex = re.compile(r'\\b(' + '|'.join(patients_set) + r')\\b')\n",
    "for column_name in range(19):\n",
    "    if any(map(lambda x: patients_regex.search(str(x)), file_df[column_name].tolist())):\n",
    "        print(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85fb854-36e8-4c3b-9b1d-391589d0d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get all the Open World logs into one data frame\n",
      "(158663, 113)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024202</th>\n",
       "      <td>11231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024211</th>\n",
       "      <td>10888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024209</th>\n",
       "      <td>10503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024224</th>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024218</th>\n",
       "      <td>10261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                record_count\n",
       "participant_id              \n",
       "2024202                11231\n",
       "2024211                10888\n",
       "2024209                10503\n",
       "2024224                10365\n",
       "2024218                10261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>184600</th>\n",
       "      <th>182194</th>\n",
       "      <th>85357</th>\n",
       "      <th>43864</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logger_version</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>2024-03-20 12:21:14</td>\n",
       "      <td>2024-03-20 14:26:07</td>\n",
       "      <td>2024-03-22 14:06:08</td>\n",
       "      <td>2024-03-14 10:48:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_scene_aborted</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_record_rotation</th>\n",
       "      <td>(0.0, -0.1, 0.0, 1.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action_tick</th>\n",
       "      <td>24324</td>\n",
       "      <td>456034</td>\n",
       "      <td>499246</td>\n",
       "      <td>751686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        184600               182194  \\\n",
       "logger_version                             1.4                  1.4   \n",
       "event_time                 2024-03-20 12:21:14  2024-03-20 14:26:07   \n",
       "is_scene_aborted                         False                False   \n",
       "patient_record_rotation  (0.0, -0.1, 0.0, 1.0)                  NaN   \n",
       "action_tick                              24324               456034   \n",
       "\n",
       "                                      85357                43864   \n",
       "logger_version                           1.4                  1.4  \n",
       "event_time               2024-03-22 14:06:08  2024-03-14 10:48:04  \n",
       "is_scene_aborted                       False                False  \n",
       "patient_record_rotation                  NaN                  NaN  \n",
       "action_tick                           499246               751686  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# In the zip there are 51 folders, (51 JSON, 51 CSV).\n",
    "# All the files are named appropriated in the folder/csv/json UUID_ParticipantID.\n",
    "# Some of the internal Participants IDs might be off because the moderator forgot to enter a Participant ID or didn't enter\n",
    "# the Participant ID correctly so we needed to figure out which participant it was.\n",
    "# So only utilize the UUID and Participant ID that is on the file name to identify and ignore the internal Participant IDs.\n",
    "print(\"\\nGet all the Open World logs into one data frame\")\n",
    "csv_stats_df = DataFrame([])\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "directories_list = listdir(logs_path)\n",
    "for dir_name in directories_list:\n",
    "    \n",
    "    # Add the CSVs to the data frame\n",
    "    folder_path = osp.join(logs_path, dir_name)\n",
    "    df = fu.concatonate_logs(logs_folder=folder_path, verbose=True)\n",
    "    \n",
    "    session_uuid, participant_id = dir_name.split('_')\n",
    "    df['session_uuid'] = session_uuid\n",
    "    df['participant_id'] = int(participant_id)\n",
    "    \n",
    "    # Remove numerically-named columns\n",
    "    columns_list = [x for x in df.columns if not search(r'\\d+', str(x))]\n",
    "    df = df[columns_list]\n",
    "    \n",
    "    # Convert 'TRUE' and 'FALSE' to boolean values\n",
    "    for cn in fu.boolean_columns_list:\n",
    "        df[cn] = df[cn].map({'TRUE': True, 'FALSE': False, 'True': True, 'False': False})\n",
    "    \n",
    "    # Convert the nulls into NaNs\n",
    "    for cn in df.columns: df[cn] = df[cn].replace(['null', 'nan', 'n'], nan)\n",
    "    \n",
    "    # Append the data frame for the current subdirectory to the main data frame and break the participant ID loop\n",
    "    csv_stats_df = concat([csv_stats_df, df], axis='index')\n",
    "\n",
    "csv_stats_df = csv_stats_df.reset_index(drop=True).drop_duplicates()\n",
    "csv_stats_df['csv_file_name'] = csv_stats_df.csv_file_subpath.map(lambda x: str(x).split('/')[-1])\n",
    "\n",
    "# Check for proper ingestion (duplicate file ingestion, et al)\n",
    "assert len(csv_stats_df.columns) > 4, \"Nothing ingested\"\n",
    "assert csv_stats_df.participant_id.nunique() == 26, f\"Participant count should be 26, it's {csv_stats_df.participant_id.nunique()} instead\"\n",
    "\n",
    "# Check that all the rows that have more than one unique value in the file_name column for each value in the session_uuid column\n",
    "mask_series = (csv_stats_df.groupby('session_uuid').csv_file_subpath.transform(Series.nunique) > 1)\n",
    "assert not mask_series.any(), \"You have duplicate files\"\n",
    "\n",
    "print(csv_stats_df.shape)\n",
    "display(csv_stats_df.groupby('participant_id').size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))\n",
    "display(csv_stats_df.sample(4).dropna(axis='columns', how='all').T.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206d0b6d-e131-4674-84a7-6304311ae490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open World Marine 1 Female Root</th>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient V Root</th>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient U Root</th>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient X Root</th>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient U Root</th>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 record_count\n",
       "patient_id                                   \n",
       "Open World Marine 1 Female Root          2313\n",
       "Patient V Root                           2052\n",
       "Patient U Root                           1900\n",
       "Patient X Root                           1003\n",
       "patient U Root                            992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Modalize separate patient ID columns into one\n",
    "new_column_name = 'patient_id'\n",
    "patient_id_columns_list = sorted(set(fu.patient_id_columns_list).intersection(set(csv_stats_df.columns)))\n",
    "csv_stats_df = nu.modalize_columns(csv_stats_df, patient_id_columns_list, new_column_name)\n",
    "display(csv_stats_df.groupby(new_column_name).size().to_frame().rename(columns={0: 'record_count'}).sort_values(\n",
    "    'record_count', ascending=False\n",
    ").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35b8296-c991-470e-b887-81e6758d613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tool_applied_row_shape', 'tool_applied_patient_id', 'tool_applied_type', 'tool_applied_attachment_point', 'tool_applied_tool_location', 'tool_applied_sender', 'tool_applied_attach_message', 'tool_applied_data', 'tag_applied_patient_id', 'tag_applied_type']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[cn for cn in csv_stats_df.columns if 'applied' in cn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0094e9-dc18-4de0-b264-3f708eec95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAG_ACCESS', 'BAG_CLOSED', 'BUTTON_CLICKED', 'PLAYER_LOCATION', 'SESSION_END', 'SESSION_START', 'SP_O2_TAKEN', 'TAG_DISCARDED', 'TAG_SELECTED', 'TELEPORT', 'TOOL_DISCARDED', 'TOOL_HOVER', 'TOOL_SELECTED', 'TRIAGE_LEVEL_WALK_IF_CAN', 'TRIAGE_LEVEL_WAVED', 'TRIAGE_LEVEL_WAVE_IF_CAN', 'VOICE_CAPTURE', 'VOICE_COMMAND']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask_series = csv_stats_df.patient_id.isnull()\n",
    "action_types_list = sorted(csv_stats_df[mask_series].action_type.unique())\n",
    "print(action_types_list)\n",
    "for action_type in action_types_list:\n",
    "    mask_series = (csv_stats_df.action_type == action_type) & ~csv_stats_df.patient_id.isnull()\n",
    "    if mask_series.any():\n",
    "        print(action_type)\n",
    "        mask_series = (csv_stats_df.action_type == action_type) & csv_stats_df.patient_id.isnull()\n",
    "        df = csv_stats_df[mask_series]\n",
    "        print(\n",
    "            f'When you are applying a tool ({action_type}) of these types you are not recording a patient ID in the logs:'\n",
    "            f' {nu.conjunctify_nouns(sorted(df.tool_applied_type.unique()))}'\n",
    "        )\n",
    "        break\n",
    "        display(df.sample(min(df.shape[0], 4)).dropna(axis='columns', how='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3b76c0b-0048-40c0-838b-89de250217de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Burn_Dressing', 'Gauze_Dressing', 'Gauze_Pack', 'IV_Blood', 'IV_Saline', 'Pain_Meds', 'SAM_Splint']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted(df.tool_applied_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30a29d1d-22a6-42ef-aaa2-8d9da8f95e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\b(IV_Blood|IV_Saline|Gauze_Dressing|Burn_Dressing|Pain_Meds|SAM_Splint|Gauze_Pack)\\b\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\\\b(' + '|'.join(df.tool_applied_type.unique()) + ')\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9116bd4-94e3-4701-9300-b319ae6c916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logs_path = osp.join(nu.data_folder, 'logs', 'Human_Sim_Metrics_Data_4-12-2024')\n",
    "for metrics_type in fu.known_mcivr_metrics_types:\n",
    "    output_file_path = osp.join(fu.saves_folder, 'csv', f'{metrics_type}.csv')\n",
    "    with open(output_file_path, mode='w', encoding=nu.encoding_type) as f: print('', file=f)\n",
    "    for dir_name in listdir(logs_path):\n",
    "        folder_path = osp.join(logs_path, dir_name)\n",
    "        for sub_directory, directories_list, files_list in walk(folder_path):\n",
    "            \n",
    "            # Iterate over the files in the current subdirectory\n",
    "            for file_name in files_list:\n",
    "                \n",
    "                # If the file is a CSV file, merge it into the subdirectory data frame\n",
    "                if file_name.endswith('.csv'):\n",
    "                    \n",
    "                    # Construct the full path to the file\n",
    "                    file_path = osp.join(sub_directory, file_name)\n",
    "                    # if (metrics_type != 'BAG_ACCESS'): print(file_path)\n",
    "                    \n",
    "                    # Read CSV file\n",
    "                    with open(file_path, 'r') as f_input:\n",
    "                        for line_str in f_input:\n",
    "                            if re.search(f'^{metrics_type},', line_str):\n",
    "                                \n",
    "                                # Add all mentions of each metrics type to its own CSV file\n",
    "                                with open(output_file_path, mode='a', encoding=nu.encoding_type) as f_output:\n",
    "                                    print(line_str, end='', file=f_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5400813f-a2f8-47bb-bb70-8b291e65d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INJURY_RECORD [5]\n",
      "INJURY_TREATED [5]\n",
      "PATIENT_DEMOTED [6]\n",
      "PATIENT_ENGAGED [6]\n",
      "BREATHING_CHECKED [5]\n",
      "PATIENT_RECORD [6]\n",
      "PULSE_TAKEN [5]\n",
      "SP_O2_TAKEN [5]\n",
      "TRIAGE_LEVEL_WALKED [6]\n",
      "TRIAGE_LEVEL_WALK_IF_CAN [6]\n",
      "TRIAGE_LEVEL_WAVED [6]\n",
      "TRIAGE_LEVEL_WAVE_IF_CAN [6]\n",
      "TAG_APPLIED [4]\n",
      "TOOL_APPLIED [4]\n",
      "PLAYER_GAZE [5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "print()\n",
    "for metrics_type in fu.known_mcivr_metrics_types:\n",
    "    \n",
    "    # Read CSV file using a CSV reader\n",
    "    output_file_path = osp.join(fu.saves_folder, 'csv', f'{metrics_type}.csv')\n",
    "    rows_list = []\n",
    "    with open(osp.abspath(output_file_path), 'r', encoding=nu.encoding_type) as f:\n",
    "        reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        for values_list in reader:\n",
    "            rows_list.append({i: v for i, v in enumerate(values_list)})\n",
    "    file_df = DataFrame(rows_list).dropna(axis='columns', how='all').dropna(axis='index', how='all')\n",
    "    # print(metrics_type, file_df.shape)\n",
    "    \n",
    "    # Show the columns that have the patient's names in them\n",
    "    patients_regex = re.compile(r'\\b(' + '|'.join(patients_set) + r')\\b')\n",
    "    column_names_list = []\n",
    "    for column_name in range(19):\n",
    "        if (column_name in file_df.columns) and any(map(lambda x: patients_regex.search(str(x)), file_df[column_name].tolist())):\n",
    "            column_names_list.append(column_name-1)\n",
    "\n",
    "    if column_names_list:\n",
    "        print(metrics_type, column_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a387140-4349-49e6-962f-390328ca5037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITM Analysis Reporting (Python 3.11.7)",
   "language": "python",
   "name": "itm_analysis_reporting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
